{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, defaultdict\n",
      "/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/pyparsing.py:2910: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile( self.reString )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "from sklearn import datasets\n",
    "import sklearn.metrics\n",
    "import shutil\n",
    "import autosklearn.classification\n",
    "import autosklearn.regression\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-394322182f88>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-394322182f88>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    def fit(self, X, y, groups)\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Inputs: X, y, regression or classification\n",
    "class base_multi_automl:\n",
    "    def __init__(self, model_type):\n",
    "        self.model_type = model_type\n",
    "        pass\n",
    "    \n",
    "    # X and y are NP matrices, assumes groups is an np vector with indicators starting from 0\n",
    "    def fit(self, X, y, groups)\n",
    "        # Split X into a list of Xs based on group assignments\n",
    "        \n",
    "                        \n",
    "        # Train each group on automl\n",
    "                \n",
    "        # Retrive a list of models bas ed on automl\n",
    "        \n",
    "        # Create a new dataset based on training each instance's groups for each model and supplying a prediction\n",
    "        \n",
    "        # Train this new dataset to get the weights for each model\n",
    "        \n",
    "        # Return a the list of models and the weights of each model\n",
    "        \n",
    "    def test(self, X, y, block_presence)\n",
    "        # X and y should be in same structure as before\n",
    "        # Block presence indicates which blocks are missing or not\n",
    "        \n",
    "        # Split X into the data groups\n",
    "        # Train each group on the saved automl models/weights\n",
    "        # Ensemble them with the group model normalized over present blocks        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pmlb import fetch_data\n",
    "\n",
    "# Returns NumPy arrays\n",
    "X, y = fetch_data('adult', return_X_y=True, local_cache_dir='./')\n",
    "groups = np.array([0, 1, 2, 1, 1, 3, 1, 3, 0, 0, 1, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m, d = np.shape(X)\n",
    "total_group_num = np.size(np.unique(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Num is 0.\n",
      "Group Num is 1.\n",
      "Group Num is 2.\n",
      "Group Num is 3.\n"
     ]
    }
   ],
   "source": [
    "# Group Splitter\n",
    "\n",
    "# Pass in X data and retrieve a list of blocks\n",
    "def create_groups(X, groups):    \n",
    "    total_group_num = np.size(np.unique(groups))    \n",
    "    group_counts = [0] * total_group_num\n",
    "    m, d = np.shape(X)\n",
    "\n",
    "    # Create a list of the groups\n",
    "    X_groups = [np.empty(1) for i in range(total_group_num)]\n",
    "    for group_num in range(total_group_num):\n",
    "        print('Group Num is {}.'.format(group_num))\n",
    "        for feature in range(d):        \n",
    "            if group_num == groups[feature]:\n",
    "                group_counts[group_num] += 1\n",
    "                if group_counts[group_num] == 1:\n",
    "                    X_groups[group_num] = np.asmatrix(X[:, feature]).T                \n",
    "                else:\n",
    "                    X_groups[group_num] = np.hstack((X_groups[group_num], np.asmatrix(X[:, feature]).T))                 \n",
    "    return X_groups, group_counts\n",
    "                \n",
    "\n",
    "X_groups, group_counts = create_groups(X_train, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36631, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_groups[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2019-04-14 15:46:23,286:EnsembleBuilder(1):16878d78c262aa5f260b41cff9e147de] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-04-14 15:46:23,298:EnsembleBuilder(1):16878d78c262aa5f260b41cff9e147de] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-04-14 15:46:25,303:EnsembleBuilder(1):16878d78c262aa5f260b41cff9e147de] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-04-14 15:46:47,860:EnsembleBuilder(1):584601c94f6dd94d45f599676e3bc094] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-04-14 15:46:47,872:EnsembleBuilder(1):584601c94f6dd94d45f599676e3bc094] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-04-14 15:46:49,876:EnsembleBuilder(1):584601c94f6dd94d45f599676e3bc094] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-04-14 15:47:12,504:EnsembleBuilder(1):54b2af14a5b0771e9f3cc58bd9d4286f] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-04-14 15:47:12,516:EnsembleBuilder(1):54b2af14a5b0771e9f3cc58bd9d4286f] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-04-14 15:47:14,520:EnsembleBuilder(1):54b2af14a5b0771e9f3cc58bd9d4286f] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-04-14 15:47:16,524:EnsembleBuilder(1):54b2af14a5b0771e9f3cc58bd9d4286f] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-04-14 15:47:18,529:EnsembleBuilder(1):54b2af14a5b0771e9f3cc58bd9d4286f] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-04-14 15:47:37,322:EnsembleBuilder(1):6922a64cc691898cd95b7a7b19d7e638] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-04-14 15:47:37,329:EnsembleBuilder(1):6922a64cc691898cd95b7a7b19d7e638] No models better than random - using Dummy Score!\n"
     ]
    }
   ],
   "source": [
    "# Training Each Group on AutoML\n",
    "time_cap = 30\n",
    "per_limit = 15\n",
    "block_models = [0] * total_group_num\n",
    "for group_num in range(total_group_num):\n",
    "    block_data = X_groups[group_num]\n",
    "    automl_model = autosklearn.classification.AutoSklearnClassifier(\n",
    "                time_left_for_this_task = time_cap,\n",
    "                per_run_time_limit = per_limit)\n",
    "    automl_model.fit(block_data, y_train)\n",
    "    block_models[group_num] = pickle.dumps(automl_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a data table for model predictions of each classifier\n",
    "def getBlockPredictions(X_groups, block_models):\n",
    "    m = X_groups[0].shape[0]\n",
    "    total_group_num = len(X_groups)\n",
    "    block_predictions = np.empty((m, total_group_num))\n",
    "    for group_num in range(total_group_num):\n",
    "        print('GROUP NUM ', group_num)\n",
    "        group_automl_model = pickle.loads(block_models[group_num])\n",
    "\n",
    "        block = X_groups[group_num]\n",
    "        block_predictions[:, group_num] = group_automl_model.predict(block)\n",
    "    return block_predictions\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUP NUM  0\n",
      "GROUP NUM  1\n",
      "GROUP NUM  2\n",
      "GROUP NUM  3\n"
     ]
    }
   ],
   "source": [
    "block_predictions = getBlockPredictions(X_groups, block_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8691818405175944"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create one final ensemble method to train on the block predictions for one final prediction\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "final_model = LogisticRegression().fit(block_predictions, y_train)\n",
    "\n",
    "# Evaluate training accuracy\n",
    "final_model.score(block_predictions, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Num is 0.\n",
      "Group Num is 1.\n",
      "Group Num is 2.\n",
      "Group Num is 3.\n",
      "GROUP NUM  0\n",
      "GROUP NUM  1\n",
      "GROUP NUM  2\n",
      "GROUP NUM  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8168864138891164"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert testing X into block predictions array and evaluate testing accuracy\n",
    "X_test_groups, group_counts = create_groups(X_test, groups)\n",
    "block_predictions_test = getBlockPredictions(X_test_groups, block_models)\n",
    "final_model.score(block_predictions_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 11, 12, 14]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:auto-sklearn]",
   "language": "python",
   "name": "conda-env-auto-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
