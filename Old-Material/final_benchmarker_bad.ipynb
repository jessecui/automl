{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Surpress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import libraries for benchmarking\n",
    "from pmlb import dataset_names, classification_dataset_names, regression_dataset_names, fetch_data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "import dill\n",
    "import sys\n",
    "import math\n",
    "\n",
    "# Import libraries for multithreading\n",
    "import time\n",
    "import shutil\n",
    "from multiprocessing import Process, current_process, Manager, Value, Pool, Array\n",
    "\n",
    "# Import SK-learn and AutoSK-Learn\n",
    "import autosklearn.classification\n",
    "import autosklearn.regression\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-c', '--class_sets'], dest='class_sets', nargs=0, const=True, default=False, type=None, choices=None, help='Benchmark on classification sets (default)', metavar=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run Auto-SkLearn on PMLB datasets')\n",
    "\n",
    "parser.add_argument('-min', '--minset', type=int, metavar='', required=False, default=1, help = 'Min dataset number (default 1)')\n",
    "parser.add_argument('-max', '--maxset', type=int, metavar='', required=False, default=166, help = '# Max dataset number (default is 166 for classifcation, 120 for regression)')\n",
    "parser.add_argument('-mem', '--memory', type=int, metavar='', required=False, default=3072, help = '# Memory capacity for the AutoSklean script (default 3072MB)')\n",
    "parser.add_argument('-noxg', '--no_xgboost', action='store_true', help = '# Remove XGBoost library from being used in Auto-SkLearn')\n",
    "parser.add_argument('-t', '--maxtime', type=int, metavar='', required=False, default=1, help = 'Maximum time to run the model for in seconds(default 3600)')\n",
    "parser.add_argument('-i', '--interval', type=int, metavar='', required=False, default=60, help = 'Interval in seconds to record data for each model')\n",
    "\n",
    "class_group = parser.add_mutually_exclusive_group()\n",
    "class_group.add_argument('-r', '--regre_sets', action='store_true', help='Benchmark on regression sets')\n",
    "class_group.add_argument('-c', '--class_sets', action='store_true', help='Benchmark on classification sets (default)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args(['-min','12','-max','13','-noxg','-t', '60', '-i', '20', '-c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign variables based on arguments\n",
    "minset = args.minset\n",
    "maxset = args.maxset\n",
    "max_time = args.maxtime\n",
    "regre_sets = args.regre_sets\n",
    "class_sets = args.class_sets\n",
    "no_xgboost = args.no_xgboost\n",
    "memory_cap = args.memory\n",
    "interval = args.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set classification sets to default if no class was selected\n",
    "if not regre_sets and not class_sets:\n",
    "    class_sets = True\n",
    "\n",
    "# Rescale dataset max number to be within boundaries\n",
    "if maxset < minset:\n",
    "    temp = maxset\n",
    "    maxset = minset\n",
    "    minset = temp\n",
    "if minset < 1:\n",
    "    minset = 1\n",
    "    print('Minset provided is less than 1, changed to 1.')\n",
    "if class_sets and maxset > 166:\n",
    "    maxset = 166\n",
    "    print('Maxset provided is greater than 166, changed to 166.')\n",
    "if regre_sets and maxset > 120:                \n",
    "    maxset = 120\n",
    "    print('Maxset provided is greater than 120, changed to 120.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "13\n",
      "60\n",
      "False\n",
      "True\n",
      "True\n",
      "3072\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(minset)\n",
    "print(maxset)\n",
    "print(max_time)\n",
    "print(regre_sets)\n",
    "print(class_sets)\n",
    "print(no_xgboost)\n",
    "print(memory_cap)\n",
    "print(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of the number of features, instances, and classes per classification dataset\n",
    "# Potentially look into including number of binary, integer, and float features in the future\n",
    "\n",
    "datasets = []\n",
    "dataset_props = {}\n",
    "\n",
    "if class_sets:\n",
    "    dataset_names = classification_dataset_names[minset-1: maxset] \n",
    "if regre_sets:\n",
    "    dataset_names = regression_dataset_names[minset-1: maxset]\n",
    "\n",
    "dataset_number = minset;\n",
    "for dataset in dataset_names:\n",
    "    X, y = fetch_data(dataset, return_X_y=True)\n",
    "    num_instances, num_features =  X.shape\n",
    "    if num_instances > 500000:\n",
    "        dataset_number += 1\n",
    "        continue        \n",
    "    num_classes = (np.unique(y)).size if class_sets else -1\n",
    "    dataset_props[dataset] = (num_instances, num_features, num_classes, dataset_number)\n",
    "    dataset_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the tmp folders where the models will take data out of\n",
    "tmp_folder = '/tmp/autosklearn_parallel_example_tmp'\n",
    "output_folder = '/tmp/autosklearn_parallel_example_out'\n",
    "\n",
    "# Clear the folders if there are contents from previous runs\n",
    "def clear_tmp_folders():\n",
    "    for dir in [tmp_folder, output_folder]:\n",
    "        try:\n",
    "            shutil.rmtree(dir)\n",
    "        except OSError as e:\n",
    "            print('Exception occurred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to run the main model on the main training data\n",
    "def run_main_model(dataset, X_train, y_train, max_time, memory_cap, tmp_folder, output_folder, interval, model_list):\n",
    "    curr_dataset_results = {}\n",
    "    # Run the classifier\n",
    "    automl = 0;\n",
    "\n",
    "    if class_sets:\n",
    "        if no_xgboost:\n",
    "            automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task = max_time,\n",
    "                                                                      ml_memory_limit = memory_cap,\n",
    "                                                                      exclude_estimators = 'xgradient_boosting.py',\n",
    "                                                                      shared_mode=True,\n",
    "                                                                      tmp_folder=tmp_folder,\n",
    "                                                                      output_folder=output_folder,\n",
    "                                                                      delete_tmp_folder_after_terminate=False,\n",
    "                                                                      delete_output_folder_after_terminate=False,\n",
    "                                                                      seed=1)\n",
    "        else:\n",
    "            automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task = max_time, \n",
    "                                                                      ml_memory_limit = memory_cap,\n",
    "                                                                      shared_mode=True,\n",
    "                                                                      tmp_folder=tmp_folder,\n",
    "                                                                      output_folder=output_folder,\n",
    "                                                                      delete_tmp_folder_after_terminate=False,\n",
    "                                                                      delete_output_folder_after_terminate=False,\n",
    "                                                                      seed=1)\n",
    "    if regre_sets:\n",
    "        if no_xgboost:\n",
    "            automl = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task = max_time, \n",
    "                                                                 ml_memory_limit = memory_cap,\n",
    "                                                                 exclude_estimators = 'xgradient_boosting.py',\n",
    "                                                                 shared_mode=True,\n",
    "                                                                 tmp_folder=tmp_folder,\n",
    "                                                                 output_folder=output_folder,\n",
    "                                                                 delete_tmp_folder_after_terminate=False,\n",
    "                                                                 delete_output_folder_after_terminate=False,\n",
    "                                                                 seed=1)\n",
    "        else:\n",
    "            automl = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task = max_time, \n",
    "                                                                 ml_memory_limit = memory_cap,\n",
    "                                                                 shared_mode=True,\n",
    "                                                                 tmp_folder=tmp_folder,\n",
    "                                                                 output_folder=output_folder,\n",
    "                                                                 delete_tmp_folder_after_terminate=False,\n",
    "                                                                 delete_output_folder_after_terminate=False,\n",
    "                                                                 seed=1)\n",
    "\n",
    "    # Use the fit and test with AutoSkLearn on the current data.\n",
    "    # If exception occurs, continue to next dataset.\n",
    "\n",
    "    print(\"Auto-SKLearn, fitting\")\n",
    "    automl.fit(X_train, y_train)\n",
    "    #model_done.value = True\n",
    "    model_list[0] = True\n",
    "    print(\"Auto-SKLearn, testing\")        \n",
    "    current_score = automl.score(X_test, y_test)                            \n",
    "    print(\"Auto-SKLearn, finished testing on set \", str(dataset_props[dataset][3]))\n",
    "    print(\"Current set Autosklearn final score: \", str(current_score))\n",
    "        \n",
    "    print(\"EXCEPTION: CURRENT DATASET FAILED WITH AUTOSKLEARN. CONTINUING TO NEXT DATASET.\")\n",
    "    #model_done.value = True\n",
    "    model_list[0] = True\n",
    "    #model_failed.value = True\n",
    "    model_list[1] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function that will be threaded periodically to take snapshots of the main model\n",
    "def snapshot_model_and_score(X_test, y_test, max_time, memory_cap, tmp_folder, output_folder, \n",
    "                             seed, curr_snap_time, dataset_props, df_rows_list, class_sets, regre_sets, interval):\n",
    "    snapshot = autosklearn.classification.AutoSklearnClassifier(\n",
    "            time_left_for_this_task=1,\n",
    "            per_run_time_limit = 1,\n",
    "            shared_mode=True, # tmp folder will be shared between seeds\n",
    "            tmp_folder=tmp_folder,\n",
    "            output_folder=output_folder,\n",
    "            delete_tmp_folder_after_terminate=False,\n",
    "            delete_output_folder_after_terminate=False,\n",
    "            seed=seed,)\n",
    "    \n",
    "    # Run the snapshot model to retrieve the model information from the temp folder\n",
    "    # This solution is not ideal even though it works. It currently does print an error because the time cap is 0.\n",
    "    try:\n",
    "        print('i')\n",
    "        snapshot.fit(X_test, y_test)\n",
    "        print('j')\n",
    "    except:\n",
    "        print('k')\n",
    "        pass\n",
    "    \n",
    "    print('l')\n",
    "    y_hat = snapshot.predict(X_test)\n",
    "    print('m')\n",
    "    accuracy_score = autosklearn.metrics.accuracy(y_test, y_hat)\n",
    "    print(f\"Current snapshot score at time {curr_snap_time}: {accuracy_score}\")    \n",
    "        \n",
    "    # Store the result in a dictionary\n",
    "    curr_dataset_results = {}\n",
    "    curr_dataset_results['name'] = dataset\n",
    "    curr_dataset_results['number'] = dataset_props[dataset][3]\n",
    "    curr_dataset_results['num_instances'] = dataset_props[dataset][0]\n",
    "    curr_dataset_results['num_features'] = dataset_props[dataset][1]\n",
    "    curr_dataset_results['num_classes'] = dataset_props[dataset][2]\n",
    "    curr_dataset_results['time_stamp'] = curr_snap_time\n",
    "    curr_dataset_results['models']  = snapshot.get_models_with_weights()\n",
    "    \n",
    "    if class_sets:\n",
    "        curr_dataset_results['accuracy'] = accuracy_score\n",
    "        curr_dataset_results['balanced_accuracy'] = autosklearn.metrics.balanced_accuracy(y_test, y_hat)\n",
    "        curr_dataset_results['f1_macro'] = autosklearn.metrics.f1_macro(y_test, y_hat)\n",
    "        curr_dataset_results['f1_micro'] = autosklearn.metrics.f1_micro(y_test, y_hat)\n",
    "        curr_dataset_results['f1_weighted'] = autosklearn.metrics.f1_weighted(y_test, y_hat)\n",
    "        curr_dataset_results['precision_macro'] = autosklearn.metrics.precision_macro(y_test, y_hat)\n",
    "        curr_dataset_results['precision_micro'] = autosklearn.metrics.precision_micro(y_test, y_hat)\n",
    "        curr_dataset_results['precision_weighted'] = autosklearn.metrics.precision_weighted(y_test, y_hat)\n",
    "        curr_dataset_results['recall_macro'] = autosklearn.metrics.recall_macro(y_test, y_hat)\n",
    "        curr_dataset_results['recall_micro'] = autosklearn.metrics.recall_micro(y_test, y_hat)\n",
    "        curr_dataset_results['recall_weighted'] = autosklearn.metrics.recall_weighted(y_test, y_hat)\n",
    "        \n",
    "    if regre_sets:\n",
    "        curr_dataset_results['r2'] = autosklearn.metrics.r2(y_test, y_hat)\n",
    "        curr_dataset_results['mean_squared_error'] = autosklearn.metrics.mean_squared_error(y_test, y_hat)\n",
    "        curr_dataset_results['mean_absolute_error'] = autosklearn.metrics.mean_absolute_error(y_test, y_hat)\n",
    "        curr_dataset_results['median_absolute_error'] = autosklearn.metrics.median_absolute_error(y_test, y_hat)\n",
    "\n",
    "    # Append current dictionary to a list of dictionary\n",
    "    df_rows_list.append(curr_dataset_results)                \n",
    "\n",
    "    # Create a Pandas Dataframe with the results\n",
    "    autosklearn_df = pd.DataFrame(list(df_rows_list))\n",
    "    autosklearn_df.sort_values(by=['number', 'time_stamp'])\n",
    "\n",
    "    # Save results into a CSV after every round\n",
    "    set_type_string = 'c' if class_sets else 'r'\n",
    "\n",
    "    file_name = 'PMLB_benchmark_results/' + set_type_string + str(dataset_props[dataset][3]) + '_' + \\\n",
    "                'maxtime' + '_' + str(max_time) + '_'+ 'interval' + '_' + str(interval) + '.csv'\n",
    "    print('saved to ', file_name)\n",
    "\n",
    "    autosklearn_df.to_csv(file_name, sep='\\t')\n",
    "    \n",
    "    # Save the pickled model\n",
    "    filename = 'Saved_models/' + set_type_string + str(dataset_props[dataset][3]) + '_' + str(max_time) + '_' + str(interval) + '.sav'\n",
    "    \n",
    "    # Send snapshot to a queue managed by the main thread to save file\n",
    "    s = pickle.dumps(snapshot)\n",
    "    #with open(filename, 'wb') as file:\n",
    "        #dill.dump(snapshot, file)\n",
    "    print('Pickled to ', filename)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allhyper', 'allhypo']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g\n",
      "Auto-SKLearn, fitting\n",
      "Auto-SKLearn, on dataset  allhyper  | Number:  12 max of  13\n",
      "Properties: \n",
      "(3771, 29, 4, 12)\n",
      "h\n",
      "base model will start\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "daemonic processes are not allowed to have children",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"<ipython-input-78-21c9d2c2e9d2>\", line 52, in run_main_model\n    automl.fit(X_train, y_train)\n  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/estimators.py\", line 500, in fit\n    dataset_name=dataset_name,\n  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/estimators.py\", line 267, in fit\n    self._automl.fit(*args, **kwargs)\n  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/automl.py\", line 965, in fit\n    only_return_configuration_space=only_return_configuration_space,\n  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/automl.py\", line 203, in fit\n    only_return_configuration_space,\n  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/automl.py\", line 363, in _fit\n    num_run = self._do_dummy_prediction(datamanager, num_run)\n  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/automl.py\", line 293, in _do_dummy_prediction\n    ta.run(1, cutoff=self._time_for_task)\n  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/evaluation/__init__.py\", line 211, in run\n    obj(**obj_kwargs)\n  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/pynisher/limit_function_call.py\", line 195, in __call__\n    subproc.start()\n  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/process.py\", line 110, in start\n    'daemonic processes are not allowed to have children'\nAssertionError: daemonic processes are not allowed to have children\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-711e4de35199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m                             \u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                             \u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                             shared_list2)])\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'base model started'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         '''\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: daemonic processes are not allowed to have children"
     ]
    }
   ],
   "source": [
    "manager = Manager()\n",
    "manager2 = Manager()\n",
    "p = Pool(4)\n",
    "\n",
    "# Add performance results of the datasets that we query on to a final dataframe to output\n",
    "for dataset in dataset_names:    \n",
    "    print('g')\n",
    "    shared_list = manager.list()\n",
    "    shared_list2 = manager2.list([0, 0])\n",
    "    # Split the data to training and test sets\n",
    "    X, y = fetch_data(dataset, return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)\n",
    "\n",
    "    clear_tmp_folders()        \n",
    "\n",
    "    print(\"Auto-SKLearn, on dataset \", dataset, \" | Number: \", str(dataset_props[dataset][3]), \"max of \", str(maxset))\n",
    "    print(\"Properties: \")    \n",
    "    print(str(dataset_props[dataset]))\n",
    "    \n",
    "    model_done = Value('b', False)\n",
    "    model_failed = Value('b', False)\n",
    "    shared_list2[0] = 0\n",
    "    shared_list2[1] = 0\n",
    "    \n",
    "    print('h')\n",
    "    # Start the base process for running the automl model\n",
    "#     base_model_process = Process(target = run_main_model, args = (dataset, \n",
    "#                                                                   X_train, \n",
    "#                                                                   y_train, \n",
    "#                                                                   max_time, \n",
    "#                                                                   memory_cap, \n",
    "#                                                                   tmp_folder, \n",
    "#                                                                   output_folder,\n",
    "#                                                                   interval,\n",
    "#                                                                   model_done,\n",
    "#                                                                   model_failed))\n",
    "\n",
    "    print('base model will start')\n",
    "    #base_model_process.start()\n",
    "    #f = lambda x: run_main_model(*x)\n",
    "    p.starmap(run_main_model, [(dataset, \n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            max_time, \n",
    "                            memory_cap, \n",
    "                            tmp_folder, \n",
    "                            output_folder,\n",
    "                            interval,\n",
    "                            shared_list2)])\n",
    "    print('base model started')\n",
    "    \n",
    "    snap_time = 0\n",
    "    # Take periodic snapshots of the model\n",
    "    while not shared_list2[0]:\n",
    "        print('Snapshotting')\n",
    "        time.sleep(interval)\n",
    "        seed = snap_time + 2\n",
    "        curr_snap_time = (snap_time+1) * interval\n",
    "        print(f'Current snap time is {curr_snap_time}')\n",
    "#         process = Process(target = snapshot_model_and_score, args = (X_test, \n",
    "#                                                                      y_test, \n",
    "#                                                                      max_time, \n",
    "#                                                                      memory_cap, \n",
    "#                                                                      tmp_folder, \n",
    "#                                                                      output_folder, \n",
    "#                                                                      seed, \n",
    "#                                                                      curr_snap_time, \n",
    "#                                                                      dataset_props, \n",
    "#                                                                      shared_list,\n",
    "#                                                                      class_sets,\n",
    "#                                                                      regre_sets,\n",
    "#                                                                      interval))\n",
    "        print('a')\n",
    "#         process.start()\n",
    "        p.map(run_main_model, [(dataset, \n",
    "                              X_train, \n",
    "                              y_train, \n",
    "                              max_time, \n",
    "                              memory_cap, \n",
    "                              tmp_folder, \n",
    "                              output_folder,\n",
    "                              interval,\n",
    "                              True,\n",
    "                              True)])\n",
    "        print('b')\n",
    "        snap_time += 1\n",
    "    # Take one last snapshot when the model is done and did not fail\n",
    "    if not shared_list2[1]:\n",
    "        print('Final Snapshot')\n",
    "        time.sleep(interval)\n",
    "        seed = snap_time + 2\n",
    "        curr_snap_time = (snap_time+1) * interval\n",
    "        print(f'Current snap time is {curr_snap_time}')\n",
    "        process = Process(target = snapshot_model_and_score, args = (X_test, \n",
    "                                                                     y_test, \n",
    "                                                                     max_time, \n",
    "                                                                     memory_cap, \n",
    "                                                                     tmp_folder, \n",
    "                                                                     output_folder, \n",
    "                                                                     seed, \n",
    "                                                                     curr_snap_time, \n",
    "                                                                     dataset_props, \n",
    "                                                                     shared_list,\n",
    "                                                                     class_sets,\n",
    "                                                                     regre_sets,\n",
    "                                                                     interval))\n",
    "        print('d')\n",
    "        process.start()\n",
    "        print('e')\n",
    "        process.join()\n",
    "        print('f')\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = pd.read_csv('PMLB_benchmark_results/c1_maxtime_1200_interval_60.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame.drop(columns=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(frame.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = Value('b', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapshot = autosklearn.classification.AutoSklearnClassifier(\n",
    "            time_left_for_this_task=1,\n",
    "            per_run_time_limit = 1,\n",
    "            shared_mode=True, # tmp folder will be shared between seeds\n",
    "            tmp_folder=tmp_folder,\n",
    "            output_folder=output_folder,\n",
    "            delete_tmp_folder_after_terminate=False,\n",
    "            delete_output_folder_after_terminate=False,\n",
    "            seed=seed,)\n",
    "try:\n",
    "    print('i')\n",
    "    snapshot.fit(X_test, y_test)\n",
    "    print('j')\n",
    "except:\n",
    "    print('k')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapshot.show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapshot.get_models_with_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:auto-sklearn]",
   "language": "python",
   "name": "conda-env-auto-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
