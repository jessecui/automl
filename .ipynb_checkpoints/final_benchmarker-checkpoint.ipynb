{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, defaultdict\n"
     ]
    }
   ],
   "source": [
    "# Surpress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import libraries for benchmarking\n",
    "from pmlb import dataset_names, classification_dataset_names, regression_dataset_names, fetch_data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "import sys\n",
    "import math\n",
    "import dill\n",
    "\n",
    "# Import libraries for multithreading\n",
    "import time\n",
    "import shutil\n",
    "from multiprocessing import Process, current_process, Manager, Value, active_children\n",
    "\n",
    "# Import SK-learn and AutoSK-Learn\n",
    "import autosklearn.classification\n",
    "import autosklearn.regression\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-c', '--class_sets'], dest='class_sets', nargs=0, const=True, default=False, type=None, choices=None, help='Benchmark on classification sets (default)', metavar=None)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read user arguments with argparse\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run Auto-SkLearn on PMLB datasets')\n",
    "\n",
    "parser.add_argument('-min', '--minset', type=int, metavar='', required=False, default=1, help = 'Min dataset number (default 1)')\n",
    "parser.add_argument('-max', '--maxset', type=int, metavar='', required=False, default=166, help = '# Max dataset number (default is 166 for classifcation, 120 for regression)')\n",
    "parser.add_argument('-mem', '--memory', type=int, metavar='', required=False, default=3072, help = '# Memory capacity for the AutoSklean script (default 3072MB)')\n",
    "parser.add_argument('-noxg', '--no_xgboost', action='store_true', help = '# Remove XGBoost library from being used in Auto-SkLearn')\n",
    "parser.add_argument('-t', '--maxtime', type=int, metavar='', required=False, default=1, help = 'Maximum time to run the model for in seconds(default 3600)')\n",
    "parser.add_argument('-i', '--interval', type=int, metavar='', required=False, default=60, help = 'Interval in seconds to record data for each model')\n",
    "\n",
    "class_group = parser.add_mutually_exclusive_group()\n",
    "class_group.add_argument('-r', '--regre_sets', action='store_true', help='Benchmark on regression sets')\n",
    "class_group.add_argument('-c', '--class_sets', action='store_true', help='Benchmark on classification sets (default)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args(['-min','1','-max','3','-noxg','-t', '120', '-i', '60', '-c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign variables based on arguments\n",
    "minset = args.minset\n",
    "maxset = args.maxset\n",
    "max_time = args.maxtime\n",
    "regre_sets = args.regre_sets\n",
    "class_sets = args.class_sets\n",
    "no_xgboost = args.no_xgboost\n",
    "memory_cap = args.memory\n",
    "interval = args.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set classification sets to default if no class was selected\n",
    "if not regre_sets and not class_sets:\n",
    "    class_sets = True\n",
    "\n",
    "# Rescale dataset max number to be within boundaries\n",
    "if maxset < minset:\n",
    "    temp = maxset\n",
    "    maxset = minset\n",
    "    minset = temp\n",
    "if minset < 1:\n",
    "    minset = 1\n",
    "    print('Minset provided is less than 1, changed to 1.')\n",
    "if class_sets and maxset > 166:\n",
    "    maxset = 166\n",
    "    print('Maxset provided is greater than 166, changed to 166.')\n",
    "if regre_sets and maxset > 120:                \n",
    "    maxset = 120\n",
    "    print('Maxset provided is greater than 120, changed to 120.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "120\n",
      "False\n",
      "True\n",
      "True\n",
      "3072\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(minset)\n",
    "print(maxset)\n",
    "print(max_time)\n",
    "print(regre_sets)\n",
    "print(class_sets)\n",
    "print(no_xgboost)\n",
    "print(memory_cap)\n",
    "print(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of the number of features, instances, and classes per classification dataset\n",
    "# Potentially look into including number of binary, integer, and float features in the future\n",
    "\n",
    "datasets = []\n",
    "dataset_props = {}\n",
    "\n",
    "if class_sets:\n",
    "    dataset_names = classification_dataset_names[minset-1: maxset] \n",
    "if regre_sets:\n",
    "    dataset_names = regression_dataset_names[minset-1: maxset]\n",
    "\n",
    "dataset_number = minset;\n",
    "for dataset in dataset_names:\n",
    "    X, y = fetch_data(dataset, return_X_y=True)\n",
    "    num_instances, num_features =  X.shape\n",
    "    if num_instances > 500000:\n",
    "        dataset_number += 1\n",
    "        continue        \n",
    "    num_classes = (np.unique(y)).size if class_sets else -1\n",
    "    dataset_props[dataset] = (num_instances, num_features, num_classes, dataset_number)\n",
    "    dataset_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the tmp folders where the models will take data out of\n",
    "tmp_folder = '/tmp/autosklearn_parallel_example_tmp'\n",
    "output_folder = '/tmp/autosklearn_parallel_example_out'\n",
    "\n",
    "# Clear the folders if there are contents from previous runs\n",
    "def clear_tmp_folders():\n",
    "    for dir in [tmp_folder, output_folder]:\n",
    "        try:\n",
    "            shutil.rmtree(dir)\n",
    "        except OSError as e:\n",
    "            print('Exception occurred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to run the main model on the main training data\n",
    "def run_main_model(dataset, X_train, y_train, max_time, memory_cap, tmp_folder, output_folder, interval, model_done, model_failed):\n",
    "    curr_dataset_results = {}\n",
    "    # Run the classifier\n",
    "    automl = 0;\n",
    "\n",
    "    if class_sets:\n",
    "        if no_xgboost:\n",
    "            automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task = max_time,\n",
    "                                                                      ml_memory_limit = memory_cap,\n",
    "                                                                      exclude_estimators = 'xgradient_boosting.py',\n",
    "                                                                      shared_mode=True,\n",
    "                                                                      tmp_folder=tmp_folder,\n",
    "                                                                      output_folder=output_folder,\n",
    "                                                                      delete_tmp_folder_after_terminate=False,\n",
    "                                                                      delete_output_folder_after_terminate=False,\n",
    "                                                                      seed=1)\n",
    "        else:\n",
    "            automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task = max_time, \n",
    "                                                                      ml_memory_limit = memory_cap,\n",
    "                                                                      shared_mode=True,\n",
    "                                                                      tmp_folder=tmp_folder,\n",
    "                                                                      output_folder=output_folder,\n",
    "                                                                      delete_tmp_folder_after_terminate=False,\n",
    "                                                                      delete_output_folder_after_terminate=False,\n",
    "                                                                      seed=1)\n",
    "    if regre_sets:\n",
    "        if no_xgboost:\n",
    "            automl = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task = max_time, \n",
    "                                                                 ml_memory_limit = memory_cap,\n",
    "                                                                 exclude_estimators = 'xgradient_boosting.py',\n",
    "                                                                 shared_mode=True,\n",
    "                                                                 tmp_folder=tmp_folder,\n",
    "                                                                 output_folder=output_folder,\n",
    "                                                                 delete_tmp_folder_after_terminate=False,\n",
    "                                                                 delete_output_folder_after_terminate=False,\n",
    "                                                                 seed=1)\n",
    "        else:\n",
    "            automl = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task = max_time, \n",
    "                                                                 ml_memory_limit = memory_cap,\n",
    "                                                                 shared_mode=True,\n",
    "                                                                 tmp_folder=tmp_folder,\n",
    "                                                                 output_folder=output_folder,\n",
    "                                                                 delete_tmp_folder_after_terminate=False,\n",
    "                                                                 delete_output_folder_after_terminate=False,\n",
    "                                                                 seed=1)\n",
    "\n",
    "    # Use the fit and test with AutoSkLearn on the current data.\n",
    "    # If exception occurs, continue to next dataset.\n",
    "    try:\n",
    "        print(\"Auto-SKLearn, fitting\")\n",
    "        automl.fit(X_train, y_train)\n",
    "        model_done.value = True\n",
    "        print(\"Auto-SKLearn, testing\")        \n",
    "        current_score = automl.score(X_test, y_test)                            \n",
    "        print(\"Auto-SKLearn, finished testing on set \", str(dataset_props[dataset][3]))\n",
    "        print(\"Current set Autosklearn final score: \", str(current_score))\n",
    "    except:        \n",
    "        print(\"EXCEPTION: CURRENT DATASET FAILED WITH AUTOSKLEARN. CONTINUING TO NEXT DATASET.\")\n",
    "        model_done.value = True\n",
    "        model_failed.value = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function that will be threaded periodically to take snapshots of the main model\n",
    "def snapshot_model_and_score(X_test, y_test, max_time, memory_cap, tmp_folder, output_folder, \n",
    "                             seed, curr_snap_time, dataset_props, df_rows_list, class_sets, regre_sets, interval):\n",
    "    if class_sets:\n",
    "        snapshot = autosklearn.classification.AutoSklearnClassifier(\n",
    "                time_left_for_this_task=15,\n",
    "                per_run_time_limit = 1,\n",
    "                shared_mode=True, # tmp folder will be shared between seeds\n",
    "                tmp_folder=tmp_folder,\n",
    "                output_folder=output_folder,\n",
    "                delete_tmp_folder_after_terminate=False,\n",
    "                delete_output_folder_after_terminate=False,\n",
    "                seed=seed,)\n",
    "    if regre_sets:\n",
    "        snapshot = autosklearn.regression.AutoSklearnRegressor(\n",
    "                time_left_for_this_task=15,\n",
    "                per_run_time_limit = 1,\n",
    "                shared_mode=True, # tmp folder will be shared between seeds\n",
    "                tmp_folder=tmp_folder,\n",
    "                output_folder=output_folder,\n",
    "                delete_tmp_folder_after_terminate=False,\n",
    "                delete_output_folder_after_terminate=False,\n",
    "                seed=seed,)            \n",
    "\n",
    "    # Run the snapshot model to retrieve the model information from the temp folder\n",
    "    # This solution is not ideal even though it works. It may print an error.\n",
    "    \n",
    "    try:\n",
    "        snapshot.fit(X_test, y_test)\n",
    "    except:\n",
    "        print(\"EXCETION ON SNAPSHOT FITTING \", str(dataset_props[dataset][3]))\n",
    "    \n",
    "    y_hat = snapshot.predict(X_test)\n",
    "    if class_sets:\n",
    "        curr_model_score = autosklearn.metrics.accuracy(y_test, y_hat)\n",
    "        print(f\"Current snapshot accuracy score at time {curr_snap_time}: {curr_model_score}\")\n",
    "        \n",
    "    if regre_sets:\n",
    "        curr_model_score = autosklearn.metrics.mean_squared_error(y_test, y_hat)\n",
    "        print(f\"Current snapshot MSE score at time {curr_snap_time}: {curr_model_score}\")    \n",
    "    \n",
    "        \n",
    "    # Store the result in a dictionary\n",
    "    curr_dataset_results = {}\n",
    "    curr_dataset_results['name'] = dataset\n",
    "    curr_dataset_results['number'] = dataset_props[dataset][3]\n",
    "    curr_dataset_results['num_instances'] = dataset_props[dataset][0]\n",
    "    curr_dataset_results['num_features'] = dataset_props[dataset][1]\n",
    "    curr_dataset_results['num_classes'] = dataset_props[dataset][2]\n",
    "    curr_dataset_results['time_stamp'] = curr_snap_time\n",
    "    curr_dataset_results['models']  = snapshot.get_models_with_weights()\n",
    "    \n",
    "    if class_sets:\n",
    "        curr_dataset_results['accuracy'] = autosklearn.metrics.accuracy(y_test, y_hat)\n",
    "        curr_dataset_results['balanced_accuracy'] = autosklearn.metrics.balanced_accuracy(y_test, y_hat)\n",
    "        curr_dataset_results['f1_macro'] = autosklearn.metrics.f1_macro(y_test, y_hat)\n",
    "        curr_dataset_results['f1_micro'] = autosklearn.metrics.f1_micro(y_test, y_hat)\n",
    "        curr_dataset_results['f1_weighted'] = autosklearn.metrics.f1_weighted(y_test, y_hat)\n",
    "        curr_dataset_results['precision_macro'] = autosklearn.metrics.precision_macro(y_test, y_hat)\n",
    "        curr_dataset_results['precision_micro'] = autosklearn.metrics.precision_micro(y_test, y_hat)\n",
    "        curr_dataset_results['precision_weighted'] = autosklearn.metrics.precision_weighted(y_test, y_hat)\n",
    "        curr_dataset_results['recall_macro'] = autosklearn.metrics.recall_macro(y_test, y_hat)\n",
    "        curr_dataset_results['recall_micro'] = autosklearn.metrics.recall_micro(y_test, y_hat)\n",
    "        curr_dataset_results['recall_weighted'] = autosklearn.metrics.recall_weighted(y_test, y_hat)\n",
    "        \n",
    "    if regre_sets:\n",
    "        curr_dataset_results['r2'] = autosklearn.metrics.r2(y_test, y_hat)\n",
    "        curr_dataset_results['mean_squared_error'] = autosklearn.metrics.mean_squared_error(y_test, y_hat)\n",
    "        curr_dataset_results['mean_absolute_error'] = autosklearn.metrics.mean_absolute_error(y_test, y_hat)\n",
    "        curr_dataset_results['median_absolute_error'] = autosklearn.metrics.median_absolute_error(y_test, y_hat)\n",
    "\n",
    "    # Append current dictionary to a list of dictionary\n",
    "    df_rows_list.append(curr_dataset_results)                \n",
    "\n",
    "    # Create a Pandas Dataframe with the results\n",
    "    autosklearn_df = pd.DataFrame(list(df_rows_list))\n",
    "    autosklearn_df.sort_values(by=['number', 'time_stamp'])\n",
    "\n",
    "    # Save results into a CSV after every round\n",
    "    set_type_string = 'c' if class_sets else 'r'\n",
    "\n",
    "    csv_file_name = 'PMLB_benchmark_results/' + set_type_string + str(dataset_props[dataset][3]) + '_' + \\\n",
    "                'maxtime' + str(max_time) + '_'+ 'interval' + str(interval) + '.csv'\n",
    "    print('saved to ', csv_file_name)\n",
    "\n",
    "    autosklearn_df.to_csv(file_name, sep='\\t')\n",
    "    \n",
    "    # Save the pickled model\n",
    "    # Cannot do this since we cannot pickle within a subprocess\n",
    "    model_file_name = 'Saved_models/' + set_type_string + str(dataset_props[dataset][3]) + '_' + 'maxtime' + str(max_time) + '_' + 'interval' + str(interval) + '.sav'    \n",
    "    dump(snapshot, model_file_name)\n",
    "    print('Successfully saved snapshot model to ', model_file_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_EDM-1_1',\n",
       " 'GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1',\n",
       " 'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Auto-SKLearn, on dataset  GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_EDM-1_1  | Number:  1 max of  3\n",
      "Properties: \n",
      "(1600, 1000, 2, 1)\n",
      "base model will start\n",
      "Auto-SKLearn, fitting\n",
      "base model started\n",
      "Snapshotting\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (119.567917)\n",
      "[WARNING] [2019-03-28 15:11:13,623:EnsembleBuilder(1):b7949df5eb6db3b08b85a9008850c8f2] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-03-28 15:11:13,636:EnsembleBuilder(1):b7949df5eb6db3b08b85a9008850c8f2] No models better than random - using Dummy Score!\n",
      "Current snap time is 60\n",
      "Snapshotting\n",
      "Current snapshot accuracy score at time 60: 0.495\n",
      "u\n",
      "saved to  PMLB_benchmark_results/c1_maxtime_120_interval_60.csv\n",
      "Successfully saved snapshot model to  Saved_models/c1_120_60.sav\n",
      "Auto-SKLearn, testing\n",
      "Auto-SKLearn, finished testing on set  1\n",
      "Current set Autosklearn final score:  0.48\n",
      "Current snap time is 120\n",
      "Final Snapshot\n",
      "Current snapshot accuracy score at time 120: 0.4975\n",
      "u\n",
      "saved to  PMLB_benchmark_results/c1_maxtime_120_interval_60.csv\n",
      "Successfully saved snapshot model to  Saved_models/c1_120_60.sav\n",
      "Taking Final Snapshot\n",
      "Current snapshot accuracy score at time 180: 0.505\n",
      "u\n",
      "saved to  PMLB_benchmark_results/c1_maxtime_120_interval_60.csv\n",
      "Successfully saved snapshot model to  Saved_models/c1_120_60.sav\n",
      "\n",
      "Auto-SKLearn, on dataset  GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1  | Number:  2 max of  3\n",
      "Properties: \n",
      "(1600, 20, 2, 2)\n",
      "base model will start\n",
      "Auto-SKLearn, fitting\n",
      "base model started\n",
      "Snapshotting\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (119.604925)\n",
      "[WARNING] [2019-03-28 15:14:26,522:EnsembleBuilder(1):ae4ce97e70e4c1eb50d3ce2b3bc89442] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-03-28 15:14:26,533:EnsembleBuilder(1):ae4ce97e70e4c1eb50d3ce2b3bc89442] No models better than random - using Dummy Score!\n",
      "Current snap time is 60\n",
      "Snapshotting\n",
      "Current snapshot accuracy score at time 60: 0.6225\n",
      "u\n",
      "saved to  PMLB_benchmark_results/c2_maxtime_120_interval_60.csv\n",
      "Successfully saved snapshot model to  Saved_models/c2_120_60.sav\n",
      "Auto-SKLearn, testing\n",
      "Auto-SKLearn, finished testing on set  2\n",
      "Current set Autosklearn final score:  0.6325\n",
      "Current snap time is 120\n",
      "Final Snapshot\n",
      "Current snapshot accuracy score at time 120: 0.6225\n",
      "u\n",
      "saved to  PMLB_benchmark_results/c2_maxtime_120_interval_60.csv\n",
      "Successfully saved snapshot model to  Saved_models/c2_120_60.sav\n",
      "Taking Final Snapshot\n",
      "Current snapshot accuracy score at time 180: 0.62\n",
      "u\n",
      "saved to  PMLB_benchmark_results/c2_maxtime_120_interval_60.csv\n",
      "Successfully saved snapshot model to  Saved_models/c2_120_60.sav\n",
      "\n",
      "Auto-SKLearn, on dataset  GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1  | Number:  3 max of  3\n",
      "Properties: \n",
      "(1600, 20, 2, 3)\n",
      "base model will start\n",
      "Auto-SKLearn, fitting\n",
      "base model started\n",
      "Snapshotting\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (119.535179)\n",
      "[WARNING] [2019-03-28 15:17:50,585:EnsembleBuilder(1):d8df8fa7dec8930acd5b6509d8dcd094] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-03-28 15:17:50,592:EnsembleBuilder(1):d8df8fa7dec8930acd5b6509d8dcd094] No models better than random - using Dummy Score!\n"
     ]
    }
   ],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Add performance results of the datasets that we query on to a final dataframe to output\n",
    "for dataset in dataset_names:    \n",
    "    shared_list = manager.list()\n",
    "    # Split the data to training and test sets\n",
    "    X, y = fetch_data(dataset, return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)\n",
    "\n",
    "    clear_tmp_folders()        \n",
    "    print(\"\")\n",
    "    print(\"Auto-SKLearn, on dataset \", dataset, \" | Number: \", str(dataset_props[dataset][3]), \"max of \", str(maxset))\n",
    "    print(\"Properties: \")    \n",
    "    print(str(dataset_props[dataset]))\n",
    "    \n",
    "    model_done = Value('b', False)\n",
    "    model_failed = Value('b', False)\n",
    "    \n",
    "    # Start the base process for running the automl model\n",
    "    base_model_process = Process(target = run_main_model, args = (dataset, \n",
    "                                                                  X_train.copy(), \n",
    "                                                                  y_train.copy(), \n",
    "                                                                  max_time, \n",
    "                                                                  memory_cap, \n",
    "                                                                  tmp_folder, \n",
    "                                                                  output_folder,\n",
    "                                                                  interval,\n",
    "                                                                  model_done,\n",
    "                                                                  model_failed))\n",
    "\n",
    "    print('base model will start')\n",
    "    base_model_process.start()\n",
    "    print('base model started')\n",
    "    \n",
    "    snap_time = 0\n",
    "    # Take periodic snapshots of the model\n",
    "    while not model_done.value:\n",
    "        print('Snapshotting')\n",
    "        time.sleep(interval)\n",
    "        seed = snap_time + 2\n",
    "        curr_snap_time = (snap_time+1) * interval\n",
    "        print(f'Current snap time is {curr_snap_time}')\n",
    "        process = Process(target = snapshot_model_and_score, args = (X_test.copy(), \n",
    "                                                                     y_test.copy(), \n",
    "                                                                     max_time, \n",
    "                                                                     memory_cap, \n",
    "                                                                     tmp_folder, \n",
    "                                                                     output_folder, \n",
    "                                                                     seed, \n",
    "                                                                     curr_snap_time, \n",
    "                                                                     dataset_props, \n",
    "                                                                     shared_list,\n",
    "                                                                     class_sets,\n",
    "                                                                     regre_sets,\n",
    "                                                                     interval))\n",
    "        process.start()\n",
    "        snap_time += 1\n",
    "    # Take one last snapshot when the model is done and did not fail\n",
    "    if not model_failed.value:\n",
    "        print('Final Snapshot')\n",
    "        time.sleep(interval)\n",
    "        seed = snap_time + 2\n",
    "        curr_snap_time = (snap_time+1) * interval\n",
    "        print('Taking Final Snapshot')\n",
    "        process = Process(target = snapshot_model_and_score, args = (X_test.copy(), \n",
    "                                                                     y_test.copy(), \n",
    "                                                                     max_time, \n",
    "                                                                     memory_cap, \n",
    "                                                                     tmp_folder, \n",
    "                                                                     output_folder, \n",
    "                                                                     seed, \n",
    "                                                                     curr_snap_time, \n",
    "                                                                     dataset_props, \n",
    "                                                                     shared_list,\n",
    "                                                                     class_sets,\n",
    "                                                                     regre_sets,\n",
    "                                                                     interval))\n",
    "        process.start()\n",
    "        process.join()      \n",
    "    \n",
    "    # Join children and print them\n",
    "    active_children()\n",
    "        \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "[CRITICAL] [2019-03-29 00:04:35,229:EnsembleBuilder(1000):b7949df5eb6db3b08b85a9008850c8f2] Changing ensemble score for file /tmp/autosklearn_parallel_example_tmp/.auto-sklearn/predictions_ensemble/predictions_ensemble_1000_2.npy from 0.505051 to 0.505051 because file modification time changed? 1553835792.833519 - 1553835874.513520\n"
     ]
    }
   ],
   "source": [
    "print('hi')\n",
    "snapshot = autosklearn.classification.AutoSklearnClassifier(\n",
    "        time_left_for_this_task=20,\n",
    "        per_run_time_limit = 1,\n",
    "        shared_mode=True, # tmp folder will be shared between seeds\n",
    "        tmp_folder=tmp_folder,\n",
    "        output_folder=output_folder,\n",
    "        delete_tmp_folder_after_terminate=False,\n",
    "        delete_output_folder_after_terminate=False,\n",
    "        seed=1000,)   \n",
    "\n",
    "# Run the snapshot model to retrieve the model information from the temp folder\n",
    "# This solution is not ideal even though it works. It may print an error.\n",
    "test = np.zeros((2,2))\n",
    "try:\n",
    "    snapshot.fit(X_test, y_test)\n",
    "except Exception as e:\n",
    "    print(\"EXCETION ON SNAPSHOT FITTING \")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6925"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = fetch_data('GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_EDM-1_1', return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (9.570382)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Configuration:\n  balancing:strategy, Value: 'none'\n  categorical_encoding:__choice__, Value: 'one_hot_encoding'\n  categorical_encoding:one_hot_encoding:minimum_fraction, Value: 0.01\n  categorical_encoding:one_hot_encoding:use_minimum_fraction, Value: 'True'\n  classifier:__choice__, Value: 'random_forest'\n  classifier:random_forest:bootstrap, Value: 'True'\n  classifier:random_forest:criterion, Value: 'gini'\n  classifier:random_forest:max_depth, Constant: 'None'\n  classifier:random_forest:max_features, Value: 0.5\n  classifier:random_forest:max_leaf_nodes, Constant: 'None'\n  classifier:random_forest:min_impurity_decrease, Constant: 0.0\n  classifier:random_forest:min_samples_leaf, Value: 1\n  classifier:random_forest:min_samples_split, Value: 2\n  classifier:random_forest:min_weight_fraction_leaf, Constant: 0.0\n  classifier:random_forest:n_estimators, Constant: 100\n  imputation:strategy, Value: 'mean'\n  preprocessor:__choice__, Value: 'no_preprocessing'\n  rescaling:__choice__, Value: 'standardize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBudgetExhaustedException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/smac/intensification/intensification.py\u001b[0m in \u001b[0;36mintensify\u001b[0;34m(self, challengers, incumbent, run_history, aggregate_func, time_bound, log_traj)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;31m# Lines 3-7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_inc_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincumbent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincumbent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/smac/intensification/intensification.py\u001b[0m in \u001b[0;36m_add_inc_run\u001b[0;34m(self, incumbent, run_history)\u001b[0m\n\u001b[1;32m    262\u001b[0m                         \u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                         instance_specific=self.instance_specifics.get(next_instance, \"0\"))\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/evaluation/__init__.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, config, instance, cutoff, seed, instance_specific, capped)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcutoff\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBudgetExhaustedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mcutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBudgetExhaustedException\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-08d1ee4c0ad9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdelete_output_folder_after_terminate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         seed=1000,)  \n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msnapshot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/estimators.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_test, y_test, metric, feat_type, dataset_name)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mfeat_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         )\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/estimators.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_automl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_automl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_automl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_test, y_test, metric, feat_type, dataset_name, only_return_configuration_space)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mfeat_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0monly_return_configuration_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monly_return_configuration_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m         )\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, task, metric, X_test, y_test, feat_type, dataset_name, only_return_configuration_space)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mloaded_data_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0monly_return_configuration_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         )\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/automl.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, datamanager, metric, only_return_configuration_space)\u001b[0m\n\u001b[1;32m    466\u001b[0m             )\n\u001b[1;32m    467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunhistory_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectory_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0m_proc_smac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_smbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             trajectory_filename = os.path.join(\n\u001b[1;32m    470\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_smac_output_directory_for_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/smbo.py\u001b[0m in \u001b[0;36mrun_smbo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0msmac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_smac_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msmac_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0msmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/smac/facade/smac_facade.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mincumbent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mincumbent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/smac/optimizer/smbo.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mfound\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \"\"\"\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Main BO loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/smac/optimizer/smbo.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mta_runs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincumbent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincumbent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mFirstRunCrashedException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_on_first_run_crash\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/smac/initial_design/multi_config_initial_design.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m                                                        \u001b[0mincumbent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                                                        \u001b[0mrun_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                                                        aggregate_func=self.aggregate_func)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/smac/intensification/intensification.py\u001b[0m in \u001b[0;36mintensify\u001b[0;34m(self, challengers, incumbent, run_history, aggregate_func, time_bound, log_traj)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBudgetExhaustedException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0;31m# We return incumbent, SMBO stops due to its own budget checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0minc_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincumbent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Budget exhausted; Return incumbent\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mincumbent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_perf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/smac/runhistory/runhistory.py\u001b[0m in \u001b[0;36mget_cost\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mComputed\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mconfig_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_per_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Configuration:\n  balancing:strategy, Value: 'none'\n  categorical_encoding:__choice__, Value: 'one_hot_encoding'\n  categorical_encoding:one_hot_encoding:minimum_fraction, Value: 0.01\n  categorical_encoding:one_hot_encoding:use_minimum_fraction, Value: 'True'\n  classifier:__choice__, Value: 'random_forest'\n  classifier:random_forest:bootstrap, Value: 'True'\n  classifier:random_forest:criterion, Value: 'gini'\n  classifier:random_forest:max_depth, Constant: 'None'\n  classifier:random_forest:max_features, Value: 0.5\n  classifier:random_forest:max_leaf_nodes, Constant: 'None'\n  classifier:random_forest:min_impurity_decrease, Constant: 0.0\n  classifier:random_forest:min_samples_leaf, Value: 1\n  classifier:random_forest:min_samples_split, Value: 2\n  classifier:random_forest:min_weight_fraction_leaf, Constant: 0.0\n  classifier:random_forest:n_estimators, Constant: 100\n  imputation:strategy, Value: 'mean'\n  preprocessor:__choice__, Value: 'no_preprocessing'\n  rescaling:__choice__, Value: 'standardize'\n"
     ]
    }
   ],
   "source": [
    "print('hi')\n",
    "snapshot = autosklearn.classification.AutoSklearnClassifier(\n",
    "        time_left_for_this_task=10,\n",
    "        per_run_time_limit = 10,\n",
    "        shared_mode=True, # tmp folder will be shared between seeds\n",
    "        tmp_folder=tmp_folder,\n",
    "        output_folder=output_folder,\n",
    "        delete_tmp_folder_after_terminate=False,\n",
    "        delete_output_folder_after_terminate=False,\n",
    "        seed=1000,)  \n",
    "snapshot.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_models_with_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d76cfbfb706c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msnapshot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_models_with_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/site-packages/autosklearn/estimators.py\u001b[0m in \u001b[0;36mget_models_with_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_automl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_models_with_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_models_with_weights'"
     ]
    }
   ],
   "source": [
    "snapshot.get_models_with_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoSklearnClassifier(delete_output_folder_after_terminate=False,\n",
       "           delete_tmp_folder_after_terminate=False,\n",
       "           disable_evaluator_output=False, ensemble_memory_limit=1024,\n",
       "           ensemble_nbest=50, ensemble_size=50, exclude_estimators=None,\n",
       "           exclude_preprocessors=None, get_smac_object_callback=None,\n",
       "           include_estimators=None, include_preprocessors=None,\n",
       "           initial_configurations_via_metalearning=25, logging_config=None,\n",
       "           ml_memory_limit=3072,\n",
       "           output_folder='/tmp/autosklearn_parallel_example_out',\n",
       "           per_run_time_limit=1, resampling_strategy='holdout',\n",
       "           resampling_strategy_arguments=None, seed=1000, shared_mode=True,\n",
       "           smac_scenario_args=None, time_left_for_this_task=20,\n",
       "           tmp_folder='/tmp/autosklearn_parallel_example_tmp')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:auto-sklearn]",
   "language": "python",
   "name": "conda-env-auto-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
