{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Surpress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import libraries for benchmarking\n",
    "from pmlb import dataset_names, classification_dataset_names, regression_dataset_names, fetch_data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "import sys\n",
    "import math\n",
    "\n",
    "# Import libraries for multithreading\n",
    "import time\n",
    "import shutil\n",
    "from multiprocessing import Process, current_process, Manager, Value\n",
    "\n",
    "# Import SK-learn and AutoSK-Learn\n",
    "import autosklearn.classification\n",
    "import autosklearn.regression\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-c', '--class_sets'], dest='class_sets', nargs=0, const=True, default=False, type=None, choices=None, help='Benchmark on classification sets (default)', metavar=None)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run Auto-SkLearn on PMLB datasets')\n",
    "\n",
    "parser.add_argument('-min', '--minset', type=int, metavar='', required=False, default=1, help = 'Min dataset number (default 1)')\n",
    "parser.add_argument('-max', '--maxset', type=int, metavar='', required=False, default=166, help = '# Max dataset number (default is 166 for classifcation, 120 for regression)')\n",
    "parser.add_argument('-mem', '--memory', type=int, metavar='', required=False, default=3072, help = '# Memory capacity for the AutoSklean script (default 3072MB)')\n",
    "parser.add_argument('-noxg', '--no_xgboost', action='store_true', help = '# Remove XGBoost library from being used in Auto-SkLearn')\n",
    "parser.add_argument('-t', '--maxtime', type=int, metavar='', required=False, default=1, help = 'Maximum time to run the model for in seconds(default 3600)')\n",
    "parser.add_argument('-i', '--interval', type=int, metavar='', required=False, default=60, help = 'Interval in seconds to record data for each model')\n",
    "\n",
    "class_group = parser.add_mutually_exclusive_group()\n",
    "class_group.add_argument('-r', '--regre_sets', action='store_true', help='Benchmark on regression sets')\n",
    "class_group.add_argument('-c', '--class_sets', action='store_true', help='Benchmark on classification sets (default)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args(['-min','12','-max','13','-noxg','-t', '60', '-i', '20', '-c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign variables based on arguments\n",
    "minset = args.minset\n",
    "maxset = args.maxset\n",
    "max_time = args.maxtime\n",
    "regre_sets = args.regre_sets\n",
    "class_sets = args.class_sets\n",
    "no_xgboost = args.no_xgboost\n",
    "memory_cap = args.memory\n",
    "interval = args.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set classification sets to default if no class was selected\n",
    "if not regre_sets and not class_sets:\n",
    "    class_sets = True\n",
    "\n",
    "# Rescale dataset max number to be within boundaries\n",
    "if maxset < minset:\n",
    "    temp = maxset\n",
    "    maxset = minset\n",
    "    minset = temp\n",
    "if minset < 1:\n",
    "    minset = 1\n",
    "    print('Minset provided is less than 1, changed to 1.')\n",
    "if class_sets and maxset > 166:\n",
    "    maxset = 166\n",
    "    print('Maxset provided is greater than 166, changed to 166.')\n",
    "if regre_sets and maxset > 120:                \n",
    "    maxset = 120\n",
    "    print('Maxset provided is greater than 120, changed to 120.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "13\n",
      "60\n",
      "False\n",
      "True\n",
      "True\n",
      "3072\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(minset)\n",
    "print(maxset)\n",
    "print(max_time)\n",
    "print(regre_sets)\n",
    "print(class_sets)\n",
    "print(no_xgboost)\n",
    "print(memory_cap)\n",
    "print(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of the number of features, instances, and classes per classification dataset\n",
    "# Potentially look into including number of binary, integer, and float features in the future\n",
    "\n",
    "datasets = []\n",
    "dataset_props = {}\n",
    "\n",
    "if class_sets:\n",
    "    dataset_names = classification_dataset_names[minset-1: maxset] \n",
    "if regre_sets:\n",
    "    dataset_names = regression_dataset_names[minset-1: maxset]\n",
    "\n",
    "dataset_number = minset;\n",
    "for dataset in dataset_names:\n",
    "    X, y = fetch_data(dataset, return_X_y=True)\n",
    "    num_instances, num_features =  X.shape\n",
    "    if num_instances > 500000:\n",
    "        dataset_number += 1\n",
    "        continue        \n",
    "    num_classes = (np.unique(y)).size if class_sets else -1\n",
    "    dataset_props[dataset] = (num_instances, num_features, num_classes, dataset_number)\n",
    "    dataset_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the tmp folders where the models will take data out of\n",
    "tmp_folder = '/tmp/autosklearn_parallel_example_tmp'\n",
    "output_folder = '/tmp/autosklearn_parallel_example_out'\n",
    "\n",
    "# Clear the folders if there are contents from previous runs\n",
    "def clear_tmp_folders():\n",
    "    for dir in [tmp_folder, output_folder]:\n",
    "        try:\n",
    "            shutil.rmtree(dir)\n",
    "        except OSError as e:\n",
    "            print('Exception occurred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to run the main model on the main training data\n",
    "def run_main_model(dataset, X_train, y_train, max_time, memory_cap, tmp_folder, output_folder, interval, model_done, model_failed):\n",
    "    curr_dataset_results = {}\n",
    "    # Run the classifier\n",
    "    automl = 0;\n",
    "\n",
    "    if class_sets:\n",
    "        if no_xgboost:\n",
    "            automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task = max_time,\n",
    "                                                                      ml_memory_limit = memory_cap,\n",
    "                                                                      exclude_estimators = 'xgradient_boosting.py',\n",
    "                                                                      shared_mode=True,\n",
    "                                                                      tmp_folder=tmp_folder,\n",
    "                                                                      output_folder=output_folder,\n",
    "                                                                      delete_tmp_folder_after_terminate=False,\n",
    "                                                                      delete_output_folder_after_terminate=False,\n",
    "                                                                      seed=1)\n",
    "        else:\n",
    "            automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task = max_time, \n",
    "                                                                      ml_memory_limit = memory_cap,\n",
    "                                                                      shared_mode=True,\n",
    "                                                                      tmp_folder=tmp_folder,\n",
    "                                                                      output_folder=output_folder,\n",
    "                                                                      delete_tmp_folder_after_terminate=False,\n",
    "                                                                      delete_output_folder_after_terminate=False,\n",
    "                                                                      seed=1)\n",
    "    if regre_sets:\n",
    "        if no_xgboost:\n",
    "            automl = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task = max_time, \n",
    "                                                                 ml_memory_limit = memory_cap,\n",
    "                                                                 exclude_estimators = 'xgradient_boosting.py',\n",
    "                                                                 shared_mode=True,\n",
    "                                                                 tmp_folder=tmp_folder,\n",
    "                                                                 output_folder=output_folder,\n",
    "                                                                 delete_tmp_folder_after_terminate=False,\n",
    "                                                                 delete_output_folder_after_terminate=False,\n",
    "                                                                 seed=1)\n",
    "        else:\n",
    "            automl = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task = max_time, \n",
    "                                                                 ml_memory_limit = memory_cap,\n",
    "                                                                 shared_mode=True,\n",
    "                                                                 tmp_folder=tmp_folder,\n",
    "                                                                 output_folder=output_folder,\n",
    "                                                                 delete_tmp_folder_after_terminate=False,\n",
    "                                                                 delete_output_folder_after_terminate=False,\n",
    "                                                                 seed=1)\n",
    "\n",
    "    # Use the fit and test with AutoSkLearn on the current data.\n",
    "    # If exception occurs, continue to next dataset.\n",
    "    try:\n",
    "        print(\"Auto-SKLearn, fitting\")\n",
    "        automl.fit(X_train, y_train)\n",
    "        model_done.value = True\n",
    "        print(\"Auto-SKLearn, testing\")        \n",
    "        current_score = automl.score(X_test, y_test)                            \n",
    "        print(\"Auto-SKLearn, finished testing on set \", str(dataset_props[dataset][3]))\n",
    "        print(\"Current set Autosklearn final score: \", str(current_score))\n",
    "    except:        \n",
    "        print(\"EXCEPTION: CURRENT DATASET FAILED WITH AUTOSKLEARN. CONTINUING TO NEXT DATASET.\")\n",
    "        model_done.value = True\n",
    "        model_failed.value = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function that will be threaded periodically to take snapshots of the main model\n",
    "def snapshot_model_and_score(X_test, y_test, max_time, memory_cap, tmp_folder, output_folder, \n",
    "                             seed, curr_snap_time, dataset_props, df_rows_list, class_sets, regre_sets, interval):\n",
    "    snapshot = autosklearn.classification.AutoSklearnClassifier(\n",
    "            time_left_for_this_task=1,\n",
    "            per_run_time_limit = 1,\n",
    "            shared_mode=True, # tmp folder will be shared between seeds\n",
    "            tmp_folder=tmp_folder,\n",
    "            output_folder=output_folder,\n",
    "            delete_tmp_folder_after_terminate=False,\n",
    "            delete_output_folder_after_terminate=False,\n",
    "            seed=seed,)\n",
    "    \n",
    "    # Run the snapshot model to retrieve the model information from the temp folder\n",
    "    # This solution is not ideal even though it works. It currently does print an error because the time cap is 0.\n",
    "    try:\n",
    "        print('i')\n",
    "        snapshot.fit(X_test, y_test)\n",
    "        print('j')\n",
    "    except:\n",
    "        print('k')\n",
    "        pass\n",
    "    \n",
    "    print('l')\n",
    "    y_hat = snapshot.predict(X_test)\n",
    "    print('m')\n",
    "    accuracy_score = autosklearn.metrics.accuracy(y_test, y_hat)\n",
    "    print(f\"Current snapshot score at time {curr_snap_time}: {accuracy_score}\")    \n",
    "        \n",
    "    # Store the result in a dictionary\n",
    "    curr_dataset_results = {}\n",
    "    curr_dataset_results['name'] = dataset\n",
    "    curr_dataset_results['number'] = dataset_props[dataset][3]\n",
    "    curr_dataset_results['num_instances'] = dataset_props[dataset][0]\n",
    "    curr_dataset_results['num_features'] = dataset_props[dataset][1]\n",
    "    curr_dataset_results['num_classes'] = dataset_props[dataset][2]\n",
    "    curr_dataset_results['time_stamp'] = curr_snap_time\n",
    "    curr_dataset_results['models']  = snapshot.get_models_with_weights()\n",
    "    \n",
    "    if class_sets:\n",
    "        curr_dataset_results['accuracy'] = accuracy_score\n",
    "        curr_dataset_results['balanced_accuracy'] = autosklearn.metrics.balanced_accuracy(y_test, y_hat)\n",
    "        curr_dataset_results['f1_macro'] = autosklearn.metrics.f1_macro(y_test, y_hat)\n",
    "        curr_dataset_results['f1_micro'] = autosklearn.metrics.f1_micro(y_test, y_hat)\n",
    "        curr_dataset_results['f1_weighted'] = autosklearn.metrics.f1_weighted(y_test, y_hat)\n",
    "        curr_dataset_results['precision_macro'] = autosklearn.metrics.precision_macro(y_test, y_hat)\n",
    "        curr_dataset_results['precision_micro'] = autosklearn.metrics.precision_micro(y_test, y_hat)\n",
    "        curr_dataset_results['precision_weighted'] = autosklearn.metrics.precision_weighted(y_test, y_hat)\n",
    "        curr_dataset_results['recall_macro'] = autosklearn.metrics.recall_macro(y_test, y_hat)\n",
    "        curr_dataset_results['recall_micro'] = autosklearn.metrics.recall_micro(y_test, y_hat)\n",
    "        curr_dataset_results['recall_weighted'] = autosklearn.metrics.recall_weighted(y_test, y_hat)\n",
    "        \n",
    "    if regre_sets:\n",
    "        curr_dataset_results['r2'] = autosklearn.metrics.r2(y_test, y_hat)\n",
    "        curr_dataset_results['mean_squared_error'] = autosklearn.metrics.mean_squared_error(y_test, y_hat)\n",
    "        curr_dataset_results['mean_absolute_error'] = autosklearn.metrics.mean_absolute_error(y_test, y_hat)\n",
    "        curr_dataset_results['median_absolute_error'] = autosklearn.metrics.median_absolute_error(y_test, y_hat)\n",
    "\n",
    "    # Append current dictionary to a list of dictionary\n",
    "    df_rows_list.append(curr_dataset_results)                \n",
    "\n",
    "    # Create a Pandas Dataframe with the results\n",
    "    autosklearn_df = pd.DataFrame(list(df_rows_list))\n",
    "    autosklearn_df.sort_values(by=['number', 'time_stamp'])\n",
    "\n",
    "    # Save results into a CSV after every round\n",
    "    set_type_string = 'c' if class_sets else 'r'\n",
    "\n",
    "    file_name = 'PMLB_benchmark_results/' + set_type_string + str(dataset_props[dataset][3]) + '_' + \\\n",
    "                'maxtime' + '_' + str(max_time) + '_'+ 'interval' + '_' + str(interval) + '.csv'\n",
    "    print('saved to ', file_name)\n",
    "\n",
    "    autosklearn_df.to_csv(file_name, sep='\\t')\n",
    "    \n",
    "    # Save the pickled model\n",
    "    filename = 'Saved_models/' + set_type_string + str(dataset_props[dataset][3]) + '_' + str(max_time) + '_' + str(interval) + '.sav'\n",
    "    \n",
    "    # Send snapshot to a queue managed by the main thread to save file\n",
    "    #dump(snapshot, filename)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allhyper', 'allhypo']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g\n",
      "Exception occurred\n",
      "Exception occurred\n",
      "Auto-SKLearn, on dataset  allhyper  | Number:  12 max of  13\n",
      "Properties: \n",
      "(3771, 29, 4, 12)\n",
      "h\n",
      "base model will start\n",
      "Auto-SKLearn, fitting\n",
      "base model started\n",
      "Snapshotting\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (59.503452)\n",
      "[WARNING] [2019-03-19 01:08:20,391:EnsembleBuilder(1):d69e8453f1e4c68a91caec41c770308e] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-03-19 01:08:20,397:EnsembleBuilder(1):d69e8453f1e4c68a91caec41c770308e] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-03-19 01:08:33,013:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2019-03-19 01:08:33,013:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "Current snap time is 20\n",
      "a\n",
      "i\n",
      "b\n",
      "Snapshotting\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (0.354000)\n",
      "[WARNING] [2019-03-19 01:08:40,815:AutoMLSMBO(2)::d69e8453f1e4c68a91caec41c770308e] Time limit for metafeature calculation less than 1 seconds (-0.044790). Skipping calculation of metafeatures for encoded dataset.\n",
      "k\n",
      "l\n",
      "m\n",
      "Current snapshot score at time 20: 0.9862142099681867\n",
      "saved to  PMLB_benchmark_results/c12_maxtime_60_interval_20.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-116:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-106-0cd413847a91>\", line 77, in snapshot_model_and_score\n",
      "    dump(snapshot, filename)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 502, in dump\n",
      "    NumpyPickler(f, protocol=protocol).dump(value)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 437, in dump\n",
      "    self.save(obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 524, in save\n",
      "    rv = reduce(self.proto)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/process.py\", line 330, in __reduce__\n",
      "    'Pickling an AuthenticationString object is '\n",
      "TypeError: Pickling an AuthenticationString object is disallowed for security reasons\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current snap time is 40\n",
      "a\n",
      "i\n",
      "b\n",
      "Snapshotting\n",
      "k\n",
      "l\n",
      "m\n",
      "Current snapshot score at time 40: 0.9893955461293743\n",
      "saved to  PMLB_benchmark_results/c12_maxtime_60_interval_20.csv\n",
      "Auto-SKLearn, testing\n",
      "Auto-SKLearn, finished testing on set  12\n",
      "Current set Autosklearn final score:  0.9893955461293743\n",
      "Current snap time is 60\n",
      "a\n",
      "i\n",
      "b\n",
      "Final Snapshot\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (0.456477)\n",
      "[WARNING] [2019-03-19 01:09:20,719:AutoMLSMBO(4)::d69e8453f1e4c68a91caec41c770308e] Time limit for metafeature calculation less than 1 seconds (-0.038889). Skipping calculation of metafeatures for encoded dataset.\n",
      "k\n",
      "l\n",
      "m\n",
      "Current snapshot score at time 60: 0.9893955461293743\n",
      "saved to  PMLB_benchmark_results/c12_maxtime_60_interval_20.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-118:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-106-0cd413847a91>\", line 77, in snapshot_model_and_score\n",
      "    dump(snapshot, filename)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 502, in dump\n",
      "    NumpyPickler(f, protocol=protocol).dump(value)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 437, in dump\n",
      "    self.save(obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 524, in save\n",
      "    rv = reduce(self.proto)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/process.py\", line 330, in __reduce__\n",
      "    'Pickling an AuthenticationString object is '\n",
      "TypeError: Pickling an AuthenticationString object is disallowed for security reasons\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current snap time is 80\n",
      "d\n",
      "i\n",
      "e\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (0.430572)\n",
      "[WARNING] [2019-03-19 01:09:40,815:AutoMLSMBO(5)::d69e8453f1e4c68a91caec41c770308e] Time limit for metafeature calculation less than 1 seconds (-0.039486). Skipping calculation of metafeatures for encoded dataset.\n",
      "k\n",
      "l\n",
      "m\n",
      "Current snapshot score at time 80: 0.9893955461293743\n",
      "saved to  PMLB_benchmark_results/c12_maxtime_60_interval_20.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-119:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-106-0cd413847a91>\", line 77, in snapshot_model_and_score\n",
      "    dump(snapshot, filename)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 502, in dump\n",
      "    NumpyPickler(f, protocol=protocol).dump(value)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 437, in dump\n",
      "    self.save(obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-6ba7d4256648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DONE!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/auto-sklearn/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 659, in save_reduce\n",
      "    self._batch_setitems(dictitems)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 659, in save_reduce\n",
      "    self._batch_setitems(dictitems)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 786, in save_tuple\n",
      "    save(element)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/site-packages/joblib/numpy_pickle.py\", line 292, in save\n",
      "    return Pickler.save(self, obj)\n",
      "  File \"/home/jcui/.conda/envs/auto-sklearn/lib/python3.7/pickle.py\", line 523, in save\n",
      "    if reduce is not None:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Add performance results of the datasets that we query on to a final dataframe to output\n",
    "for dataset in dataset_names:    \n",
    "    print('g')\n",
    "    shared_list = manager.list()\n",
    "    # Split the data to training and test sets\n",
    "    X, y = fetch_data(dataset, return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)\n",
    "\n",
    "    clear_tmp_folders()        \n",
    "\n",
    "    print(\"Auto-SKLearn, on dataset \", dataset, \" | Number: \", str(dataset_props[dataset][3]), \"max of \", str(maxset))\n",
    "    print(\"Properties: \")    \n",
    "    print(str(dataset_props[dataset]))\n",
    "    \n",
    "    model_done = Value('b', False)\n",
    "    model_failed = Value('b', False)\n",
    "    \n",
    "    print('h')\n",
    "    # Start the base process for running the automl model\n",
    "    base_model_process = Process(target = run_main_model, args = (dataset, \n",
    "                                                                  X_train, \n",
    "                                                                  y_train, \n",
    "                                                                  max_time, \n",
    "                                                                  memory_cap, \n",
    "                                                                  tmp_folder, \n",
    "                                                                  output_folder,\n",
    "                                                                  interval,\n",
    "                                                                  model_done,\n",
    "                                                                  model_failed))\n",
    "\n",
    "    print('base model will start')\n",
    "    base_model_process.start()\n",
    "    print('base model started')\n",
    "    \n",
    "    snap_time = 0\n",
    "    # Take periodic snapshots of the model\n",
    "    while not model_done.value:\n",
    "        print('Snapshotting')\n",
    "        time.sleep(interval)\n",
    "        seed = snap_time + 2\n",
    "        curr_snap_time = (snap_time+1) * interval\n",
    "        print(f'Current snap time is {curr_snap_time}')\n",
    "        process = Process(target = snapshot_model_and_score, args = (X_test, \n",
    "                                                                     y_test, \n",
    "                                                                     max_time, \n",
    "                                                                     memory_cap, \n",
    "                                                                     tmp_folder, \n",
    "                                                                     output_folder, \n",
    "                                                                     seed, \n",
    "                                                                     curr_snap_time, \n",
    "                                                                     dataset_props, \n",
    "                                                                     shared_list,\n",
    "                                                                     class_sets,\n",
    "                                                                     regre_sets,\n",
    "                                                                     interval))\n",
    "        print('a')\n",
    "        process.start()\n",
    "        print('b')\n",
    "        snap_time += 1\n",
    "    # Take one last snapshot when the model is done and did not fail\n",
    "    if not model_failed.value:\n",
    "        print('Final Snapshot')\n",
    "        time.sleep(interval)\n",
    "        seed = snap_time + 2\n",
    "        curr_snap_time = (snap_time+1) * interval\n",
    "        print(f'Current snap time is {curr_snap_time}')\n",
    "        process = Process(target = snapshot_model_and_score, args = (X_test, \n",
    "                                                                     y_test, \n",
    "                                                                     max_time, \n",
    "                                                                     memory_cap, \n",
    "                                                                     tmp_folder, \n",
    "                                                                     output_folder, \n",
    "                                                                     seed, \n",
    "                                                                     curr_snap_time, \n",
    "                                                                     dataset_props, \n",
    "                                                                     shared_list,\n",
    "                                                                     class_sets,\n",
    "                                                                     regre_sets,\n",
    "                                                                     interval))\n",
    "        print('d')\n",
    "        process.start()\n",
    "        print('e')\n",
    "        process.join()\n",
    "        print('f')\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = pd.read_csv('PMLB_benchmark_results/c1_maxtime_1200_interval_60.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>num_features</th>\n",
       "      <th>num_instances</th>\n",
       "      <th>number</th>\n",
       "      <th>time_stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.510154</td>\n",
       "      <td>0.561247</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.510154</td>\n",
       "      <td>0.561247</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.510154</td>\n",
       "      <td>0.561247</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.510154</td>\n",
       "      <td>0.561247</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.510154</td>\n",
       "      <td>0.561247</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  accuracy  balanced_accuracy        f1  num_classes  \\\n",
       "0            0    0.5225           0.521259  0.485175            2   \n",
       "1            1    0.5225           0.521259  0.485175            2   \n",
       "2            2    0.5225           0.521259  0.485175            2   \n",
       "3            3    0.5225           0.521259  0.485175            2   \n",
       "4            4    0.5225           0.521259  0.485175            2   \n",
       "5            5    0.5225           0.521259  0.485175            2   \n",
       "6            6    0.5225           0.521259  0.485175            2   \n",
       "7            7    0.5225           0.521259  0.485175            2   \n",
       "8            8    0.5225           0.521259  0.485175            2   \n",
       "9            9    0.5225           0.521259  0.485175            2   \n",
       "10          10    0.5225           0.521259  0.485175            2   \n",
       "11          11    0.5225           0.521259  0.485175            2   \n",
       "12          12    0.5225           0.521259  0.485175            2   \n",
       "13          13    0.5225           0.521259  0.485175            2   \n",
       "14          14    0.5225           0.521259  0.485175            2   \n",
       "15          15    0.5225           0.521259  0.485175            2   \n",
       "16          16    0.5075           0.510154  0.561247            2   \n",
       "17          17    0.5075           0.510154  0.561247            2   \n",
       "18          18    0.5075           0.510154  0.561247            2   \n",
       "19          19    0.5075           0.510154  0.561247            2   \n",
       "20          20    0.5075           0.510154  0.561247            2   \n",
       "\n",
       "    num_features  num_instances  number  time_stamp  \n",
       "0           1000           1600       1          60  \n",
       "1           1000           1600       1         120  \n",
       "2           1000           1600       1         180  \n",
       "3           1000           1600       1         240  \n",
       "4           1000           1600       1         300  \n",
       "5           1000           1600       1         360  \n",
       "6           1000           1600       1         420  \n",
       "7           1000           1600       1         480  \n",
       "8           1000           1600       1         540  \n",
       "9           1000           1600       1         600  \n",
       "10          1000           1600       1         660  \n",
       "11          1000           1600       1         720  \n",
       "12          1000           1600       1         780  \n",
       "13          1000           1600       1         840  \n",
       "14          1000           1600       1         900  \n",
       "15          1000           1600       1         960  \n",
       "16          1000           1600       1        1020  \n",
       "17          1000           1600       1        1080  \n",
       "18          1000           1600       1        1140  \n",
       "19          1000           1600       1        1200  \n",
       "20          1000           1600       1        1260  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.drop(columns=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(frame.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = Value('b', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'automl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-d343331b4437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'automl' is not defined"
     ]
    }
   ],
   "source": [
    "automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (0.515802)\n",
      "[WARNING] [2019-03-19 00:52:35,068:AutoMLSMBO(5)::779b24e31f34c8b64a66cb8bad56eb2b] Time limit for metafeature calculation less than 1 seconds (-0.038076). Skipping calculation of metafeatures for encoded dataset.\n",
      "k\n"
     ]
    }
   ],
   "source": [
    "snapshot = autosklearn.classification.AutoSklearnClassifier(\n",
    "            time_left_for_this_task=1,\n",
    "            per_run_time_limit = 1,\n",
    "            shared_mode=True, # tmp folder will be shared between seeds\n",
    "            tmp_folder=tmp_folder,\n",
    "            output_folder=output_folder,\n",
    "            delete_tmp_folder_after_terminate=False,\n",
    "            delete_output_folder_after_terminate=False,\n",
    "            seed=seed,)\n",
    "try:\n",
    "    print('i')\n",
    "    snapshot.fit(X_test, y_test)\n",
    "    print('j')\n",
    "except:\n",
    "    print('k')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(0.700000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.01},\\ndataset_properties={\\n  'task': 2,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': True,\\n  'target_type': 'classification',\\n  'signed': False})),\\n(0.080000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'feature_agglomeration', 'rescaling:__choice__': 'robust_scaler', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'False', 'classifier:random_forest:criterion': 'entropy', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5565918060287016, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 5, 'classifier:random_forest:min_samples_split': 18, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'preprocessor:feature_agglomeration:affinity': 'cosine', 'preprocessor:feature_agglomeration:linkage': 'complete', 'preprocessor:feature_agglomeration:n_clusters': 173, 'preprocessor:feature_agglomeration:pooling_func': 'max', 'rescaling:robust_scaler:q_max': 0.9527068489270145, 'rescaling:robust_scaler:q_min': 0.04135311355893583, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.0053329726928195206},\\ndataset_properties={\\n  'task': 2,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': True,\\n  'target_type': 'classification',\\n  'signed': False})),\\n(0.080000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'libsvm_svc', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'polynomial', 'rescaling:__choice__': 'robust_scaler', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:libsvm_svc:C': 56.086963007482865, 'classifier:libsvm_svc:gamma': 0.013609964993119375, 'classifier:libsvm_svc:kernel': 'rbf', 'classifier:libsvm_svc:max_iter': -1, 'classifier:libsvm_svc:shrinking': 'True', 'classifier:libsvm_svc:tol': 0.00196831255706268, 'preprocessor:polynomial:degree': 2, 'preprocessor:polynomial:include_bias': 'True', 'preprocessor:polynomial:interaction_only': 'False', 'rescaling:robust_scaler:q_max': 0.75, 'rescaling:robust_scaler:q_min': 0.15374716583918388, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.010000000000000004},\\ndataset_properties={\\n  'task': 2,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': True,\\n  'target_type': 'classification',\\n  'signed': False})),\\n(0.040000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'k_nearest_neighbors', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'standardize', 'classifier:k_nearest_neighbors:n_neighbors': 1, 'classifier:k_nearest_neighbors:p': 2, 'classifier:k_nearest_neighbors:weights': 'uniform'},\\ndataset_properties={\\n  'task': 2,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': True,\\n  'target_type': 'classification',\\n  'signed': False})),\\n(0.040000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'extra_trees', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'feature_agglomeration', 'rescaling:__choice__': 'minmax', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:extra_trees:bootstrap': 'False', 'classifier:extra_trees:criterion': 'gini', 'classifier:extra_trees:max_depth': 'None', 'classifier:extra_trees:max_features': 0.9094110110427254, 'classifier:extra_trees:max_leaf_nodes': 'None', 'classifier:extra_trees:min_impurity_decrease': 0.0, 'classifier:extra_trees:min_samples_leaf': 7, 'classifier:extra_trees:min_samples_split': 12, 'classifier:extra_trees:min_weight_fraction_leaf': 0.0, 'classifier:extra_trees:n_estimators': 100, 'preprocessor:feature_agglomeration:affinity': 'manhattan', 'preprocessor:feature_agglomeration:linkage': 'complete', 'preprocessor:feature_agglomeration:n_clusters': 195, 'preprocessor:feature_agglomeration:pooling_func': 'mean', 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.18137532678800652},\\ndataset_properties={\\n  'task': 2,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': True,\\n  'target_type': 'classification',\\n  'signed': False})),\\n(0.040000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'libsvm_svc', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'feature_agglomeration', 'rescaling:__choice__': 'normalize', 'classifier:libsvm_svc:C': 252.46150431953347, 'classifier:libsvm_svc:gamma': 5.0356168121062, 'classifier:libsvm_svc:kernel': 'rbf', 'classifier:libsvm_svc:max_iter': -1, 'classifier:libsvm_svc:shrinking': 'True', 'classifier:libsvm_svc:tol': 2.797954243297303e-05, 'preprocessor:feature_agglomeration:affinity': 'manhattan', 'preprocessor:feature_agglomeration:linkage': 'average', 'preprocessor:feature_agglomeration:n_clusters': 47, 'preprocessor:feature_agglomeration:pooling_func': 'median'},\\ndataset_properties={\\n  'task': 2,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': True,\\n  'target_type': 'classification',\\n  'signed': False})),\\n(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'liblinear_svc_preprocessor', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'False', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.7983157215145903, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 4, 'classifier:random_forest:min_samples_split': 15, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'preprocessor:liblinear_svc_preprocessor:C': 0.4971515945303584, 'preprocessor:liblinear_svc_preprocessor:dual': 'False', 'preprocessor:liblinear_svc_preprocessor:fit_intercept': 'True', 'preprocessor:liblinear_svc_preprocessor:intercept_scaling': 1, 'preprocessor:liblinear_svc_preprocessor:loss': 'squared_hinge', 'preprocessor:liblinear_svc_preprocessor:multi_class': 'ovr', 'preprocessor:liblinear_svc_preprocessor:penalty': 'l1', 'preprocessor:liblinear_svc_preprocessor:tol': 0.00010268311046018636, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.001856820833094005},\\ndataset_properties={\\n  'task': 2,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': True,\\n  'target_type': 'classification',\\n  'signed': False})),\\n]\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7,\n",
       "  SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.01},\n",
       "  dataset_properties={\n",
       "    'task': 2,\n",
       "    'sparse': False,\n",
       "    'multilabel': False,\n",
       "    'multiclass': True,\n",
       "    'target_type': 'classification',\n",
       "    'signed': False})),\n",
       " (0.08,\n",
       "  SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'feature_agglomeration', 'rescaling:__choice__': 'robust_scaler', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'False', 'classifier:random_forest:criterion': 'entropy', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5565918060287016, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 5, 'classifier:random_forest:min_samples_split': 18, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'preprocessor:feature_agglomeration:affinity': 'cosine', 'preprocessor:feature_agglomeration:linkage': 'complete', 'preprocessor:feature_agglomeration:n_clusters': 173, 'preprocessor:feature_agglomeration:pooling_func': 'max', 'rescaling:robust_scaler:q_max': 0.9527068489270145, 'rescaling:robust_scaler:q_min': 0.04135311355893583, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.0053329726928195206},\n",
       "  dataset_properties={\n",
       "    'task': 2,\n",
       "    'sparse': False,\n",
       "    'multilabel': False,\n",
       "    'multiclass': True,\n",
       "    'target_type': 'classification',\n",
       "    'signed': False})),\n",
       " (0.08,\n",
       "  SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'libsvm_svc', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'polynomial', 'rescaling:__choice__': 'robust_scaler', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:libsvm_svc:C': 56.086963007482865, 'classifier:libsvm_svc:gamma': 0.013609964993119375, 'classifier:libsvm_svc:kernel': 'rbf', 'classifier:libsvm_svc:max_iter': -1, 'classifier:libsvm_svc:shrinking': 'True', 'classifier:libsvm_svc:tol': 0.00196831255706268, 'preprocessor:polynomial:degree': 2, 'preprocessor:polynomial:include_bias': 'True', 'preprocessor:polynomial:interaction_only': 'False', 'rescaling:robust_scaler:q_max': 0.75, 'rescaling:robust_scaler:q_min': 0.15374716583918388, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.010000000000000004},\n",
       "  dataset_properties={\n",
       "    'task': 2,\n",
       "    'sparse': False,\n",
       "    'multilabel': False,\n",
       "    'multiclass': True,\n",
       "    'target_type': 'classification',\n",
       "    'signed': False})),\n",
       " (0.04,\n",
       "  SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'k_nearest_neighbors', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'standardize', 'classifier:k_nearest_neighbors:n_neighbors': 1, 'classifier:k_nearest_neighbors:p': 2, 'classifier:k_nearest_neighbors:weights': 'uniform'},\n",
       "  dataset_properties={\n",
       "    'task': 2,\n",
       "    'sparse': False,\n",
       "    'multilabel': False,\n",
       "    'multiclass': True,\n",
       "    'target_type': 'classification',\n",
       "    'signed': False})),\n",
       " (0.04,\n",
       "  SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'extra_trees', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'feature_agglomeration', 'rescaling:__choice__': 'minmax', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:extra_trees:bootstrap': 'False', 'classifier:extra_trees:criterion': 'gini', 'classifier:extra_trees:max_depth': 'None', 'classifier:extra_trees:max_features': 0.9094110110427254, 'classifier:extra_trees:max_leaf_nodes': 'None', 'classifier:extra_trees:min_impurity_decrease': 0.0, 'classifier:extra_trees:min_samples_leaf': 7, 'classifier:extra_trees:min_samples_split': 12, 'classifier:extra_trees:min_weight_fraction_leaf': 0.0, 'classifier:extra_trees:n_estimators': 100, 'preprocessor:feature_agglomeration:affinity': 'manhattan', 'preprocessor:feature_agglomeration:linkage': 'complete', 'preprocessor:feature_agglomeration:n_clusters': 195, 'preprocessor:feature_agglomeration:pooling_func': 'mean', 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.18137532678800652},\n",
       "  dataset_properties={\n",
       "    'task': 2,\n",
       "    'sparse': False,\n",
       "    'multilabel': False,\n",
       "    'multiclass': True,\n",
       "    'target_type': 'classification',\n",
       "    'signed': False})),\n",
       " (0.04,\n",
       "  SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'libsvm_svc', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'feature_agglomeration', 'rescaling:__choice__': 'normalize', 'classifier:libsvm_svc:C': 252.46150431953347, 'classifier:libsvm_svc:gamma': 5.0356168121062, 'classifier:libsvm_svc:kernel': 'rbf', 'classifier:libsvm_svc:max_iter': -1, 'classifier:libsvm_svc:shrinking': 'True', 'classifier:libsvm_svc:tol': 2.797954243297303e-05, 'preprocessor:feature_agglomeration:affinity': 'manhattan', 'preprocessor:feature_agglomeration:linkage': 'average', 'preprocessor:feature_agglomeration:n_clusters': 47, 'preprocessor:feature_agglomeration:pooling_func': 'median'},\n",
       "  dataset_properties={\n",
       "    'task': 2,\n",
       "    'sparse': False,\n",
       "    'multilabel': False,\n",
       "    'multiclass': True,\n",
       "    'target_type': 'classification',\n",
       "    'signed': False})),\n",
       " (0.02,\n",
       "  SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'liblinear_svc_preprocessor', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'False', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.7983157215145903, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 4, 'classifier:random_forest:min_samples_split': 15, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'preprocessor:liblinear_svc_preprocessor:C': 0.4971515945303584, 'preprocessor:liblinear_svc_preprocessor:dual': 'False', 'preprocessor:liblinear_svc_preprocessor:fit_intercept': 'True', 'preprocessor:liblinear_svc_preprocessor:intercept_scaling': 1, 'preprocessor:liblinear_svc_preprocessor:loss': 'squared_hinge', 'preprocessor:liblinear_svc_preprocessor:multi_class': 'ovr', 'preprocessor:liblinear_svc_preprocessor:penalty': 'l1', 'preprocessor:liblinear_svc_preprocessor:tol': 0.00010268311046018636, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.001856820833094005},\n",
       "  dataset_properties={\n",
       "    'task': 2,\n",
       "    'sparse': False,\n",
       "    'multilabel': False,\n",
       "    'multiclass': True,\n",
       "    'target_type': 'classification',\n",
       "    'signed': False}))]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.get_models_with_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:auto-sklearn]",
   "language": "python",
   "name": "conda-env-auto-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
