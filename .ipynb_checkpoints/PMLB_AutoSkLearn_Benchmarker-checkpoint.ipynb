{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Surpress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pmlb import dataset_names, fetch_data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "\n",
    "# Import SK-learn and AutoSK-Learn\n",
    "import autosklearn.classification\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-c', '--class_sets'], dest='class_sets', nargs=0, const=True, default=False, type=None, choices=None, help='Benchmark on classification sets', metavar=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Argument Parsers for the following:\n",
    "\n",
    "# Min dataset number (default is 1)\n",
    "# Max dataset number (default is 166 for classifcation, 120 for regression)\n",
    "# Mutually exclusive argument for classification vs regression dataset\n",
    "# List of number of seconds to train datasets on (default is 3600)\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run Auto-SkLearn on PMLB datasets')\n",
    "\n",
    "parser.add_argument('-min', '--minset', type=int, metavar='', required=False, default=1, help = 'Min dataset number (default 1)')\n",
    "parser.add_argument('-max', '--maxset', type=int, metavar='', required=False, default=166, help = '# Max dataset number (default is 166 for classifcation, 120 for regression)')\n",
    "parser.add_argument('-t', '--times', type=int, nargs='+', metavar='', required=False, default=3600, help = 'List of number of seconds to train datasets on (default is 3600)')\n",
    "\n",
    "class_group = parser.add_mutually_exclusive_group()\n",
    "class_group.add_argument('-r', '--regre_sets', action='store_true', help='Benchmark on regression sets')\n",
    "class_group.add_argument('-c', '--class_sets', action='store_true', help='Benchmark on classification sets (default)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10\n",
      "[80, 120]\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(['-min', '1', '-max', '10', '-t', '80', '120'])\n",
    "\n",
    "# Assign variables based on arguments\n",
    "minset = args.minset\n",
    "maxset = args.maxset\n",
    "times = args.times\n",
    "regre_sets = args.regre_sets\n",
    "class_sets = args.class_sets\n",
    "\n",
    "# Set classification sets to default if no class was selected\n",
    "\n",
    "if not regre_sets and not class_sets:\n",
    "    class_sets = True\n",
    "\n",
    "# Rescale dataset max number to be within boundaries\n",
    "if minset < 1:\n",
    "    minset = 1\n",
    "    print('Minset provided is less than 1, changed to 1.')\n",
    "if class_sets and maxset > 166:\n",
    "    maxset = 166\n",
    "    print('Maxset provided is greater than 166, changed to 166.')\n",
    "if regre_sets and maxset > 120:                \n",
    "    maxset = 120\n",
    "    print('Maxset provided is greater than 120, changed to 120.')    \n",
    "    \n",
    "print(minset)\n",
    "print(maxset)\n",
    "print(times)\n",
    "print(regre_sets)\n",
    "print(class_sets)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of the number of features, instances, and classes per classification dataset\n",
    "# Potentially look into including number of binary, integer, and float features in the future\n",
    "\n",
    "datasets = []\n",
    "dataset_props = {}\n",
    "\n",
    "if class_sets:\n",
    "    dataset_names = classification_dataset_names[minset-1: maxset]    \n",
    "if regre_sets:\n",
    "    dataset_names = regression_dataset_names[minset-1: maxset]\n",
    "\n",
    "dataset_number = minset;\n",
    "for dataset in dataset_names:\n",
    "    X, y = fetch_data(dataset, return_X_y=True)\n",
    "    num_instances, num_features =  X.shape\n",
    "    num_classes = (np.unique(y)).size    \n",
    "    dataset_props[dataset] = (num_instances, num_features, num_classes, dataset_number)\n",
    "    dataset_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GAMETES_Epistasis_2-Way_1000atts_0.4H_EDM-1_EDM-1_1': (1600, 1000, 2, 1),\n",
       " 'GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1': (1600, 20, 2, 2),\n",
       " 'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1': (1600, 20, 2, 3),\n",
       " 'GAMETES_Epistasis_3-Way_20atts_0.2H_EDM-1_1': (1600, 20, 2, 4),\n",
       " 'GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM-2_001': (1600,\n",
       "  20,\n",
       "  2,\n",
       "  5),\n",
       " 'GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM-2_001': (1600,\n",
       "  20,\n",
       "  2,\n",
       "  6),\n",
       " 'Hill_Valley_with_noise': (1212, 100, 2, 7),\n",
       " 'Hill_Valley_without_noise': (1212, 100, 2, 8),\n",
       " 'adult': (48842, 14, 2, 9),\n",
       " 'agaricus-lepiota': (8145, 22, 2, 10)}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TIME IS  100\n",
      "Auto-SKLearn, on dataset  GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1  | Number:  2 out of  4\n",
      "Properties: \n",
      "(1479, 8, 9, 2)\n",
      "Auto-SKLearn, fitting\n",
      "[WARNING] [2019-02-24 15:43:02,714:EnsembleBuilder(1):ae4ce97e70e4c1eb50d3ce2b3bc89442] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-02-24 15:43:02,724:EnsembleBuilder(1):ae4ce97e70e4c1eb50d3ce2b3bc89442] No models better than random - using Dummy Score!\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (99.425137)\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:31] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "[15:43:32] /workspace/src/gbm/gbtree.cc:492: drop 0 trees, weight = 1\n",
      "Auto-SKLearn, testing\n",
      "Auto-SKLearn, finished testing on set  2\n",
      "Current time Autosklearn score:  0.6275\n",
      "Auto-SKLearn, on dataset  GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1  | Number:  3 out of  4\n",
      "Properties: \n",
      "(1479, 8, 9, 3)\n",
      "Auto-SKLearn, fitting\n",
      "[WARNING] [2019-02-24 15:44:38,223:EnsembleBuilder(1):d8df8fa7dec8930acd5b6509d8dcd094] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-02-24 15:44:38,236:EnsembleBuilder(1):d8df8fa7dec8930acd5b6509d8dcd094] No models better than random - using Dummy Score!\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (99.561659)\n",
      "Auto-SKLearn, testing\n",
      "Auto-SKLearn, finished testing on set  3\n",
      "Current time Autosklearn score:  0.7575\n",
      "Auto-SKLearn, on dataset  GAMETES_Epistasis_3-Way_20atts_0.2H_EDM-1_1  | Number:  4 out of  4\n",
      "Properties: \n",
      "(1479, 8, 9, 4)\n",
      "Auto-SKLearn, fitting\n",
      "[WARNING] [2019-02-24 15:46:13,950:EnsembleBuilder(1):7b0e98ac1277d30dffc08b6807d04be4] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-02-24 15:46:13,960:EnsembleBuilder(1):7b0e98ac1277d30dffc08b6807d04be4] No models better than random - using Dummy Score!\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (99.457895)\n",
      "Auto-SKLearn, testing\n",
      "Auto-SKLearn, finished testing on set  4\n",
      "Current time Autosklearn score:  0.55\n",
      "CURRENT TIME IS  200\n",
      "Auto-SKLearn, on dataset  GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1  | Number:  2 out of  4\n",
      "Properties: \n",
      "(1479, 8, 9, 2)\n",
      "Auto-SKLearn, fitting\n",
      "[WARNING] [2019-02-24 15:47:49,507:EnsembleBuilder(1):ae4ce97e70e4c1eb50d3ce2b3bc89442] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-02-24 15:47:49,513:EnsembleBuilder(1):ae4ce97e70e4c1eb50d3ce2b3bc89442] No models better than random - using Dummy Score!\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (199.458481)\n",
      "Auto-SKLearn, testing\n",
      "Auto-SKLearn, finished testing on set  2\n",
      "Current time Autosklearn score:  0.6275\n",
      "Auto-SKLearn, on dataset  GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1  | Number:  3 out of  4\n",
      "Properties: \n",
      "(1479, 8, 9, 3)\n",
      "Auto-SKLearn, fitting\n",
      "[WARNING] [2019-02-24 15:51:05,201:EnsembleBuilder(1):d8df8fa7dec8930acd5b6509d8dcd094] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-02-24 15:51:05,211:EnsembleBuilder(1):d8df8fa7dec8930acd5b6509d8dcd094] No models better than random - using Dummy Score!\n",
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (199.589170)\n",
      "[WARNING] [2019-02-24 15:52:28,284:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2019-02-24 15:52:28,284:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "Auto-SKLearn, testing\n",
      "Auto-SKLearn, finished testing on set  3\n",
      "Current time Autosklearn score:  0.725\n",
      "Auto-SKLearn, on dataset  GAMETES_Epistasis_3-Way_20atts_0.2H_EDM-1_1  | Number:  4 out of  4\n",
      "Properties: \n",
      "(1479, 8, 9, 4)\n",
      "Auto-SKLearn, fitting\n",
      "[WARNING] [2019-02-24 15:54:21,298:EnsembleBuilder(1):7b0e98ac1277d30dffc08b6807d04be4] No models better than random - using Dummy Score!\n",
      "[WARNING] [2019-02-24 15:54:21,306:EnsembleBuilder(1):7b0e98ac1277d30dffc08b6807d04be4] No models better than random - using Dummy Score!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (199.505947)\n",
      "Auto-SKLearn, testing\n",
      "Auto-SKLearn, finished testing on set  4\n",
      "Current time Autosklearn score:  0.6075\n"
     ]
    }
   ],
   "source": [
    "# Add to this dataframe the performance results of the datasets that we query on\n",
    "df_rows_list = []\n",
    "for time_cap in times:\n",
    "    print('CURRENT TIME IS ', time_cap)\n",
    "        \n",
    "    for dataset in dataset_names:\n",
    "        curr_dataset_results = {}\n",
    "        print(\"Auto-SKLearn, on dataset \", dataset, \" | Number: \", str(dataset_props[dataset][3]), \"max of \", str(maxset))\n",
    "        print(\"Properties: \")\n",
    "        print(str(dataset_props[dataset]))\n",
    "        \n",
    "        # Split the data to training and test sets\n",
    "        X, y = fetch_data(dataset, return_X_y=True)\n",
    "        X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)\n",
    "\n",
    "        # Run the classifier\n",
    "        automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task = time_cap)\n",
    "        print(\"Auto-SKLearn, fitting\")\n",
    "        automl.fit(X_train, y_train)\n",
    "        print(\"Auto-SKLearn, testing\")        \n",
    "        current_score = automl.score(X_test, y_test)                            \n",
    "        print(\"Auto-SKLearn, finished testing on set \", str(dataset_props[dataset][3]))\n",
    "        print(\"Current time Autosklearn score: \", str(current_score))\n",
    "              \n",
    "        # Store the result in a dictionary\n",
    "        curr_dataset_results['name'] = dataset\n",
    "        curr_dataset_results['number'] = dataset_props[dataset][3]\n",
    "        curr_dataset_results['num_instances'] = dataset_props[dataset][0]\n",
    "        curr_dataset_results['num_features'] = dataset_props[dataset][1]\n",
    "        curr_dataset_results['num_classes'] = dataset_props[dataset][2]\n",
    "        curr_dataset_results['time_cap'] = time_cap\n",
    "        curr_dataset_results['score'] = current_score\n",
    "              \n",
    "        # Append current dictionary to a list of dictionary\n",
    "        df_rows_list.append(curr_dataset_results)                   \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "autosklearn_df = pd.DataFrame(df_rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>num_features</th>\n",
       "      <th>num_instances</th>\n",
       "      <th>number</th>\n",
       "      <th>score</th>\n",
       "      <th>time_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1479</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1479</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7575</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GAMETES_Epistasis_3-Way_20atts_0.2H_EDM-1_1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1479</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1479</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1479</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GAMETES_Epistasis_3-Way_20atts_0.2H_EDM-1_1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1479</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name  num_classes  num_features  \\\n",
       "0  GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1            9             8   \n",
       "1  GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1            9             8   \n",
       "2  GAMETES_Epistasis_3-Way_20atts_0.2H_EDM-1_1            9             8   \n",
       "3  GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1            9             8   \n",
       "4  GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1            9             8   \n",
       "5  GAMETES_Epistasis_3-Way_20atts_0.2H_EDM-1_1            9             8   \n",
       "\n",
       "   num_instances  number   score  time_cap  \n",
       "0           1479       2  0.6275       100  \n",
       "1           1479       3  0.7575       100  \n",
       "2           1479       4  0.5500       100  \n",
       "3           1479       2  0.6275       200  \n",
       "4           1479       3  0.7250       200  \n",
       "5           1479       4  0.6075       200  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autosklearn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to  c_2_4_times_100_200.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results into a CSV\n",
    "set_type_string = 'c' if class_sets else 'r'\n",
    "\n",
    "times_string = ''\n",
    "\n",
    "for i in range(len(times)):\n",
    "    times_string += str(times[i])\n",
    "    if i != len(times) - 1:\n",
    "        times_string += '_'\n",
    "\n",
    "file_name = set_type_string + '_' + str(minset) + '_' + str(maxset) + '_' + 'times' + '_' + times_string + '.csv'\n",
    "print('saving to ', file_name)\n",
    "\n",
    "autosklearn_df.to_csv(file_name, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:auto-sklearn]",
   "language": "python",
   "name": "conda-env-auto-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
